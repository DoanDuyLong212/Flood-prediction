{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-28T06:47:00.564459Z",
     "iopub.status.busy": "2025-06-28T06:47:00.564211Z",
     "iopub.status.idle": "2025-06-28T06:47:28.759921Z",
     "shell.execute_reply": "2025-06-28T06:47:28.759147Z",
     "shell.execute_reply.started": "2025-06-28T06:47:00.564431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import re\n",
    "import ast\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:47:28.762219Z",
     "iopub.status.busy": "2025-06-28T06:47:28.761660Z",
     "iopub.status.idle": "2025-06-28T06:47:28.765853Z",
     "shell.execute_reply": "2025-06-28T06:47:28.765216Z",
     "shell.execute_reply.started": "2025-06-28T06:47:28.762197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMG_DIR = '../data/devset_images/devset_images'\n",
    "META_JSON = '../data/devset_images_metadata.json'\n",
    "GT_CSV = '../data/devset_images_gt.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:47:28.766816Z",
     "iopub.status.busy": "2025-06-28T06:47:28.766624Z",
     "iopub.status.idle": "2025-06-28T06:47:28.832720Z",
     "shell.execute_reply": "2025-06-28T06:47:28.832159Z",
     "shell.execute_reply.started": "2025-06-28T06:47:28.766800Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:47:28.833693Z",
     "iopub.status.busy": "2025-06-28T06:47:28.833465Z",
     "iopub.status.idle": "2025-06-28T06:47:38.112120Z",
     "shell.execute_reply": "2025-06-28T06:47:38.111261Z",
     "shell.execute_reply.started": "2025-06-28T06:47:28.833670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72b183df4564e24b761c5f07b9a6ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ACER\\.cache\\huggingface\\hub\\models--microsoft--git-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0fe5782d0b42a0bf175b43a39c7d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/453 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be558f82c2f34456a87ecaac0deded5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3f16d514f44aa6a4a4d597b62f8325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629c15098c71474f8f9ffbc7a204a188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df98c6584cf44a299bdee4a6b21fa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ae838c031e400a96349ac7df90e020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2143aa6bd0674b6c85f8997f28e42d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GitForCausalLM(\n",
       "  (git): GitModel(\n",
       "    (embeddings): GitEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(1024, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (image_encoder): GitVisionModel(\n",
       "      (vision_model): GitVisionTransformer(\n",
       "        (embeddings): GitVisionEmbeddings(\n",
       "          (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "          (position_embedding): Embedding(257, 1024)\n",
       "        )\n",
       "        (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder): GitVisionEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-23): 24 x GitVisionEncoderLayer(\n",
       "              (self_attn): GitVisionAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): GitVisionMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder): GitEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x GitLayer(\n",
       "          (attention): GitAttention(\n",
       "            (self): GitSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): GitSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): GitIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): GitOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (visual_projection): GitProjection(\n",
       "      (visual_projection): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=768, bias=True)\n",
       "        (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=768, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422a9ec7069847c487e403573a7c6d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "\n",
    "processor_git2 = AutoProcessor.from_pretrained(\"microsoft/git-large\")\n",
    "model_git2 = AutoModelForCausalLM.from_pretrained(\"microsoft/git-large\").to(DEVICE)\n",
    "model_git2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:47:38.114013Z",
     "iopub.status.busy": "2025-06-28T06:47:38.113091Z",
     "iopub.status.idle": "2025-06-28T06:47:38.533972Z",
     "shell.execute_reply": "2025-06-28T06:47:38.533136Z",
     "shell.execute_reply.started": "2025-06-28T06:47:38.113969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(META_JSON, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "train_data = json_data['images']\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "# Clean columns\n",
    "cols_needed = ['image_id', 'title', 'description', 'user_tags']\n",
    "train_df = train_df[[col for col in cols_needed if col in train_df.columns]]\n",
    "train_df = train_df.rename(columns={'image_id': 'id'})\n",
    "train_df['id'] = train_df['id'].astype(int)\n",
    "\n",
    "# Clean user_tags\n",
    "train_df[\"user_tags\"] = train_df[\"user_tags\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "train_df[\"user_tags\"] = train_df[\"user_tags\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else str(x))\n",
    "\n",
    "# Basic text clean\n",
    "def basic_clean(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"\", text)\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s\\u4e00-\\u9fff\\u3040-\\u30ff\\uac00-\\ud7af\\-_#]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "for col in ['title', 'description', 'user_tags']:\n",
    "    train_df[col] = train_df[col].fillna(\"\").astype(str).apply(basic_clean)\n",
    "\n",
    "train_df[\"text\"] = train_df.apply(lambda row: f\"Title: {row['title']} | Description: {row['description']} | Tags: {row['user_tags']}\", axis=1)\n",
    "\n",
    "# Merge label\n",
    "label_df = pd.read_csv(GT_CSV)\n",
    "label_df['id'] = label_df['id'].apply(lambda x: int(float(x)))\n",
    "train_df = train_df.merge(label_df, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:47:38.535623Z",
     "iopub.status.busy": "2025-06-28T06:47:38.535014Z",
     "iopub.status.idle": "2025-06-28T06:47:38.540407Z",
     "shell.execute_reply": "2025-06-28T06:47:38.539500Z",
     "shell.execute_reply.started": "2025-06-28T06:47:38.535601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_image_path(image_id, exts=[\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"]):\n",
    "    for ext in exts:\n",
    "        path = os.path.join(IMG_DIR, f\"{image_id}{ext}\")\n",
    "        if os.path.isfile(path):\n",
    "            return path\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:47:38.544711Z",
     "iopub.status.busy": "2025-06-28T06:47:38.544294Z",
     "iopub.status.idle": "2025-06-28T06:47:38.558516Z",
     "shell.execute_reply": "2025-06-28T06:47:38.557744Z",
     "shell.execute_reply.started": "2025-06-28T06:47:38.544692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_git2_feature(image_path, text, fallback_dim=768):\n",
    "    try:\n",
    "        from PIL import Image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Cắt bớt text nếu quá dài\n",
    "        text = \" \".join(text.split()[:80])\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = processor_git2(images=image, text=text, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "        # Forward GIT-2\n",
    "        outputs = model_git2(**inputs, output_hidden_states=True)\n",
    "\n",
    "        # Trích đặc trưng từ token cuối ở layer cuối\n",
    "        feature = outputs.hidden_states[-1][:, -1, :]  # shape (1, hidden_dim)\n",
    "\n",
    "        return feature.squeeze(0).cpu().numpy()  # shape (hidden_dim,)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"GIT-2 lỗi ảnh: {image_path} | {e}\")\n",
    "        return np.zeros(fallback_dim, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:47:38.560388Z",
     "iopub.status.busy": "2025-06-28T06:47:38.559821Z",
     "iopub.status.idle": "2025-06-28T06:54:11.586405Z",
     "shell.execute_reply": "2025-06-28T06:54:11.585738Z",
     "shell.execute_reply.started": "2025-06-28T06:47:38.560359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting GIT-2 features:  98%|█████████▊| 5178/5280 [09:01<00:10,  9.51it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "Extracting GIT-2 features: 100%|██████████| 5280/5280 [09:11<00:00,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 5280 success, 0 missing images, 0 invalid features, 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "error_count = 0\n",
    "missing_image_count = 0\n",
    "invalid_feature_count = 0\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "expected_shape = (768,)\n",
    "\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Extracting GIT-2 features\"):\n",
    "    try:\n",
    "        image_id = str(int(row['id']))\n",
    "        image_path = find_image_path(image_id)\n",
    "        text_input = row.get('text', '')\n",
    "\n",
    "        feature = None\n",
    "        if image_path is not None:\n",
    "            feature = extract_git2_feature(image_path, text_input, fallback_dim=expected_shape[0])\n",
    "\n",
    "        if feature is None or not isinstance(feature, np.ndarray) or feature.shape != expected_shape:\n",
    "            if len(all_features) > 0:\n",
    "                feature = np.mean(all_features, axis=0)\n",
    "            else:\n",
    "                feature = np.zeros(expected_shape, dtype=np.float32)\n",
    "\n",
    "            if image_path is None:\n",
    "                print(f\"Không tìm thấy ảnh ID {image_id}, gán vector trung bình.\")\n",
    "                missing_image_count += 1\n",
    "            else:\n",
    "                print(f\"Feature lỗi ID {image_id}, gán vector trung bình.\")\n",
    "                invalid_feature_count += 1\n",
    "\n",
    "        all_features.append(feature)\n",
    "        all_labels.append(row['label'])\n",
    "        success_count += 1\n",
    "\n",
    "        if idx % 200 == 0:\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi tại idx {idx} (ID {row['id']}): {e}\")\n",
    "        error_count += 1\n",
    "\n",
    "X = np.stack(all_features)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "print(f\"Done: {success_count} success, {missing_image_count} missing images, {invalid_feature_count} invalid features, {error_count} errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:11.587336Z",
     "iopub.status.busy": "2025-06-28T06:54:11.587116Z",
     "iopub.status.idle": "2025-06-28T06:54:11.602092Z",
     "shell.execute_reply": "2025-06-28T06:54:11.601413Z",
     "shell.execute_reply.started": "2025-06-28T06:54:11.587313Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (5280, 768)\n",
      "Label shape  : (5280,)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "print(\"Feature shape:\", X.shape)\n",
    "print(\"Label shape  :\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:11.603077Z",
     "iopub.status.busy": "2025-06-28T06:54:11.602813Z",
     "iopub.status.idle": "2025-06-28T06:54:11.610872Z",
     "shell.execute_reply": "2025-06-28T06:54:11.610194Z",
     "shell.execute_reply.started": "2025-06-28T06:54:11.603059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FusionNetGIT2(nn.Module):\n",
    "    def __init__(self, input_dim=768):\n",
    "        super(FusionNetGIT2, self).__init__()\n",
    "        self.bn_input = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 384)\n",
    "        self.bn2 = nn.BatchNorm1d(384)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc3 = nn.Linear(384, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.dropout4 = nn.Dropout(0.05)\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn_input(x)\n",
    "\n",
    "        x = F.silu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.silu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.silu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = F.silu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        return self.out(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:11.611871Z",
     "iopub.status.busy": "2025-06-28T06:54:11.611620Z",
     "iopub.status.idle": "2025-06-28T06:54:11.635147Z",
     "shell.execute_reply": "2025-06-28T06:54:11.634365Z",
     "shell.execute_reply.started": "2025-06-28T06:54:11.611850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, Subset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "pos_weight = torch.tensor(3360 / 1920, dtype=torch.float32).to(DEVICE)  # điều chỉnh nếu cần\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "dataset = TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:11.636128Z",
     "iopub.status.busy": "2025-06-28T06:54:11.635858Z",
     "iopub.status.idle": "2025-06-28T06:54:11.646718Z",
     "shell.execute_reply": "2025-06-28T06:54:11.646185Z",
     "shell.execute_reply.started": "2025-06-28T06:54:11.636111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_fold(model, train_loader, val_loader, fold_id, total_epochs=50, lr_max=0.00068):\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr_max, weight_decay=0.001)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3, min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_threshold = 0.5\n",
    "    patience = 9\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        all_probs, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                preds = model(xb)\n",
    "                probs = torch.sigmoid(preds).cpu().numpy().flatten()\n",
    "                all_probs.extend(probs)\n",
    "                all_targets.extend(yb.cpu().numpy().flatten())\n",
    "\n",
    "        probs = np.array(all_probs)\n",
    "        targets = np.array(all_targets)\n",
    "\n",
    "        def find_best_threshold(y_true, y_prob):\n",
    "            thresholds = np.arange(0.1, 0.91, 0.01)\n",
    "            best_t, best_f1 = 0.5, 0.0\n",
    "            for t in thresholds:\n",
    "                preds = (y_prob >= t).astype(int)\n",
    "                f1 = f1_score(y_true, preds, zero_division=0)\n",
    "                if f1 > best_f1:\n",
    "                    best_t, best_f1 = t, f1\n",
    "            return best_t, best_f1\n",
    "\n",
    "        best_threshold_epoch, best_f1_epoch = find_best_threshold(targets, probs)\n",
    "\n",
    "        # Log\n",
    "        auc = roc_auc_score(targets, probs)\n",
    "        f1 = f1_score(targets, (probs >= 0.5).astype(int), zero_division=0)\n",
    "        precision = precision_score(targets, (probs >= 0.5).astype(int), zero_division=0)\n",
    "        recall = recall_score(targets, (probs >= 0.5).astype(int), zero_division=0)\n",
    "        acc = (targets == (probs >= 0.5).astype(int)).mean()\n",
    "\n",
    "        scheduler.step(f1)\n",
    "\n",
    "        print(f\"[Fold {fold_id}] Epoch {epoch+1}: F1 = {f1:.4f} | AUC = {auc:.4f} | \"\n",
    "              f\"Best Threshold = {best_threshold_epoch:.2f} | Best F1 = {best_f1_epoch:.4f}\")\n",
    "\n",
    "        if best_f1_epoch > best_f1:\n",
    "            best_f1 = best_f1_epoch\n",
    "            best_threshold = best_threshold_epoch\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_fold{fold_id}.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "\n",
    "    return best_threshold, probs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:11.647867Z",
     "iopub.status.busy": "2025-06-28T06:54:11.647379Z",
     "iopub.status.idle": "2025-06-28T06:54:52.455919Z",
     "shell.execute_reply": "2025-06-28T06:54:52.455326Z",
     "shell.execute_reply.started": "2025-06-28T06:54:11.647850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "[Fold 1] Epoch 1: F1 = 0.8808 | AUC = 0.9655 | Best Threshold = 0.55 | Best F1 = 0.8883\n",
      "[Fold 1] Epoch 2: F1 = 0.8861 | AUC = 0.9723 | Best Threshold = 0.53 | Best F1 = 0.8972\n",
      "[Fold 1] Epoch 3: F1 = 0.8957 | AUC = 0.9722 | Best Threshold = 0.57 | Best F1 = 0.9058\n",
      "[Fold 1] Epoch 4: F1 = 0.8628 | AUC = 0.9679 | Best Threshold = 0.65 | Best F1 = 0.8936\n",
      "[Fold 1] Epoch 5: F1 = 0.8821 | AUC = 0.9632 | Best Threshold = 0.53 | Best F1 = 0.8883\n",
      "[Fold 1] Epoch 6: F1 = 0.8607 | AUC = 0.9674 | Best Threshold = 0.74 | Best F1 = 0.8877\n",
      "[Fold 1] Epoch 7: F1 = 0.8918 | AUC = 0.9699 | Best Threshold = 0.49 | Best F1 = 0.8946\n",
      "[Fold 1] Epoch 8: F1 = 0.8895 | AUC = 0.9686 | Best Threshold = 0.55 | Best F1 = 0.8906\n",
      "[Fold 1] Epoch 9: F1 = 0.8854 | AUC = 0.9702 | Best Threshold = 0.54 | Best F1 = 0.8901\n",
      "[Fold 1] Epoch 10: F1 = 0.8831 | AUC = 0.9647 | Best Threshold = 0.44 | Best F1 = 0.8860\n",
      "[Fold 1] Epoch 11: F1 = 0.8848 | AUC = 0.9692 | Best Threshold = 0.42 | Best F1 = 0.8941\n",
      "[Fold 1] Epoch 12: F1 = 0.8992 | AUC = 0.9690 | Best Threshold = 0.49 | Best F1 = 0.8997\n",
      "\n",
      "Fold 2\n",
      "[Fold 2] Epoch 1: F1 = 0.8900 | AUC = 0.9826 | Best Threshold = 0.75 | Best F1 = 0.9149\n",
      "[Fold 2] Epoch 2: F1 = 0.9109 | AUC = 0.9858 | Best Threshold = 0.53 | Best F1 = 0.9154\n",
      "[Fold 2] Epoch 3: F1 = 0.9137 | AUC = 0.9857 | Best Threshold = 0.44 | Best F1 = 0.9181\n",
      "[Fold 2] Epoch 4: F1 = 0.9266 | AUC = 0.9844 | Best Threshold = 0.49 | Best F1 = 0.9266\n",
      "[Fold 2] Epoch 5: F1 = 0.9143 | AUC = 0.9836 | Best Threshold = 0.54 | Best F1 = 0.9186\n",
      "[Fold 2] Epoch 6: F1 = 0.9063 | AUC = 0.9846 | Best Threshold = 0.59 | Best F1 = 0.9215\n",
      "[Fold 2] Epoch 7: F1 = 0.9082 | AUC = 0.9807 | Best Threshold = 0.38 | Best F1 = 0.9136\n",
      "[Fold 2] Epoch 8: F1 = 0.8992 | AUC = 0.9820 | Best Threshold = 0.36 | Best F1 = 0.9091\n",
      "[Fold 2] Epoch 9: F1 = 0.9188 | AUC = 0.9843 | Best Threshold = 0.57 | Best F1 = 0.9203\n",
      "[Fold 2] Epoch 10: F1 = 0.9171 | AUC = 0.9831 | Best Threshold = 0.47 | Best F1 = 0.9199\n",
      "[Fold 2] Epoch 11: F1 = 0.9119 | AUC = 0.9840 | Best Threshold = 0.72 | Best F1 = 0.9206\n",
      "[Fold 2] Epoch 12: F1 = 0.9109 | AUC = 0.9831 | Best Threshold = 0.59 | Best F1 = 0.9271\n",
      "[Fold 2] Epoch 13: F1 = 0.9146 | AUC = 0.9830 | Best Threshold = 0.69 | Best F1 = 0.9275\n",
      "[Fold 2] Epoch 14: F1 = 0.9013 | AUC = 0.9804 | Best Threshold = 0.78 | Best F1 = 0.9206\n",
      "[Fold 2] Epoch 15: F1 = 0.9152 | AUC = 0.9840 | Best Threshold = 0.65 | Best F1 = 0.9288\n",
      "[Fold 2] Epoch 16: F1 = 0.9262 | AUC = 0.9813 | Best Threshold = 0.50 | Best F1 = 0.9262\n",
      "[Fold 2] Epoch 17: F1 = 0.9282 | AUC = 0.9827 | Best Threshold = 0.47 | Best F1 = 0.9309\n",
      "[Fold 2] Epoch 18: F1 = 0.9169 | AUC = 0.9832 | Best Threshold = 0.79 | Best F1 = 0.9271\n",
      "[Fold 2] Epoch 19: F1 = 0.9239 | AUC = 0.9829 | Best Threshold = 0.51 | Best F1 = 0.9262\n",
      "[Fold 2] Epoch 20: F1 = 0.9188 | AUC = 0.9824 | Best Threshold = 0.43 | Best F1 = 0.9227\n",
      "[Fold 2] Epoch 21: F1 = 0.9175 | AUC = 0.9816 | Best Threshold = 0.22 | Best F1 = 0.9231\n",
      "[Fold 2] Epoch 22: F1 = 0.9207 | AUC = 0.9826 | Best Threshold = 0.34 | Best F1 = 0.9254\n",
      "[Fold 2] Epoch 23: F1 = 0.9173 | AUC = 0.9815 | Best Threshold = 0.84 | Best F1 = 0.9235\n",
      "[Fold 2] Epoch 24: F1 = 0.9196 | AUC = 0.9822 | Best Threshold = 0.57 | Best F1 = 0.9266\n",
      "[Fold 2] Epoch 25: F1 = 0.9211 | AUC = 0.9824 | Best Threshold = 0.62 | Best F1 = 0.9247\n",
      "[Fold 2] Epoch 26: F1 = 0.9184 | AUC = 0.9825 | Best Threshold = 0.66 | Best F1 = 0.9291\n",
      "\n",
      "Fold 3\n",
      "[Fold 3] Epoch 1: F1 = 0.8714 | AUC = 0.9786 | Best Threshold = 0.71 | Best F1 = 0.9138\n",
      "[Fold 3] Epoch 2: F1 = 0.9063 | AUC = 0.9838 | Best Threshold = 0.68 | Best F1 = 0.9129\n",
      "[Fold 3] Epoch 3: F1 = 0.8992 | AUC = 0.9814 | Best Threshold = 0.63 | Best F1 = 0.9091\n",
      "[Fold 3] Epoch 4: F1 = 0.9100 | AUC = 0.9818 | Best Threshold = 0.54 | Best F1 = 0.9171\n",
      "[Fold 3] Epoch 5: F1 = 0.8985 | AUC = 0.9807 | Best Threshold = 0.59 | Best F1 = 0.9186\n",
      "[Fold 3] Epoch 6: F1 = 0.8946 | AUC = 0.9824 | Best Threshold = 0.66 | Best F1 = 0.9120\n",
      "[Fold 3] Epoch 7: F1 = 0.9171 | AUC = 0.9803 | Best Threshold = 0.50 | Best F1 = 0.9171\n",
      "[Fold 3] Epoch 8: F1 = 0.8922 | AUC = 0.9801 | Best Threshold = 0.60 | Best F1 = 0.9147\n",
      "[Fold 3] Epoch 9: F1 = 0.8967 | AUC = 0.9827 | Best Threshold = 0.88 | Best F1 = 0.9169\n",
      "[Fold 3] Epoch 10: F1 = 0.8934 | AUC = 0.9802 | Best Threshold = 0.62 | Best F1 = 0.9191\n",
      "[Fold 3] Epoch 11: F1 = 0.9091 | AUC = 0.9822 | Best Threshold = 0.46 | Best F1 = 0.9119\n",
      "[Fold 3] Epoch 12: F1 = 0.9105 | AUC = 0.9833 | Best Threshold = 0.43 | Best F1 = 0.9199\n",
      "[Fold 3] Epoch 13: F1 = 0.9175 | AUC = 0.9794 | Best Threshold = 0.51 | Best F1 = 0.9199\n",
      "[Fold 3] Epoch 14: F1 = 0.9019 | AUC = 0.9752 | Best Threshold = 0.48 | Best F1 = 0.9048\n",
      "[Fold 3] Epoch 15: F1 = 0.9171 | AUC = 0.9784 | Best Threshold = 0.48 | Best F1 = 0.9171\n",
      "[Fold 3] Epoch 16: F1 = 0.9124 | AUC = 0.9803 | Best Threshold = 0.52 | Best F1 = 0.9195\n",
      "[Fold 3] Epoch 17: F1 = 0.9044 | AUC = 0.9816 | Best Threshold = 0.88 | Best F1 = 0.9115\n",
      "[Fold 3] Epoch 18: F1 = 0.9044 | AUC = 0.9791 | Best Threshold = 0.47 | Best F1 = 0.9128\n",
      "[Fold 3] Epoch 19: F1 = 0.9072 | AUC = 0.9779 | Best Threshold = 0.52 | Best F1 = 0.9119\n",
      "[Fold 3] Epoch 20: F1 = 0.9062 | AUC = 0.9801 | Best Threshold = 0.42 | Best F1 = 0.9100\n",
      "[Fold 3] Epoch 21: F1 = 0.8997 | AUC = 0.9763 | Best Threshold = 0.83 | Best F1 = 0.9125\n",
      "\n",
      "Fold 4\n",
      "[Fold 4] Epoch 1: F1 = 0.8741 | AUC = 0.9702 | Best Threshold = 0.51 | Best F1 = 0.8783\n",
      "[Fold 4] Epoch 2: F1 = 0.8544 | AUC = 0.9651 | Best Threshold = 0.74 | Best F1 = 0.8686\n",
      "[Fold 4] Epoch 3: F1 = 0.8717 | AUC = 0.9717 | Best Threshold = 0.48 | Best F1 = 0.8750\n",
      "[Fold 4] Epoch 4: F1 = 0.8557 | AUC = 0.9632 | Best Threshold = 0.54 | Best F1 = 0.8643\n",
      "[Fold 4] Epoch 5: F1 = 0.8658 | AUC = 0.9678 | Best Threshold = 0.73 | Best F1 = 0.8825\n",
      "[Fold 4] Epoch 6: F1 = 0.8543 | AUC = 0.9633 | Best Threshold = 0.68 | Best F1 = 0.8654\n",
      "[Fold 4] Epoch 7: F1 = 0.8600 | AUC = 0.9670 | Best Threshold = 0.43 | Best F1 = 0.8719\n",
      "[Fold 4] Epoch 8: F1 = 0.8586 | AUC = 0.9606 | Best Threshold = 0.65 | Best F1 = 0.8660\n",
      "[Fold 4] Epoch 9: F1 = 0.8531 | AUC = 0.9642 | Best Threshold = 0.38 | Best F1 = 0.8625\n",
      "[Fold 4] Epoch 10: F1 = 0.8691 | AUC = 0.9656 | Best Threshold = 0.54 | Best F1 = 0.8778\n",
      "[Fold 4] Epoch 11: F1 = 0.8680 | AUC = 0.9643 | Best Threshold = 0.54 | Best F1 = 0.8718\n",
      "[Fold 4] Epoch 12: F1 = 0.8741 | AUC = 0.9650 | Best Threshold = 0.48 | Best F1 = 0.8775\n",
      "[Fold 4] Epoch 13: F1 = 0.8642 | AUC = 0.9636 | Best Threshold = 0.55 | Best F1 = 0.8700\n",
      "[Fold 4] Epoch 14: F1 = 0.8741 | AUC = 0.9633 | Best Threshold = 0.51 | Best F1 = 0.8762\n",
      "\n",
      "Fold 5\n",
      "[Fold 5] Epoch 1: F1 = 0.8720 | AUC = 0.9762 | Best Threshold = 0.76 | Best F1 = 0.8918\n",
      "[Fold 5] Epoch 2: F1 = 0.8988 | AUC = 0.9794 | Best Threshold = 0.72 | Best F1 = 0.9129\n",
      "[Fold 5] Epoch 3: F1 = 0.8922 | AUC = 0.9772 | Best Threshold = 0.77 | Best F1 = 0.9067\n",
      "[Fold 5] Epoch 4: F1 = 0.9039 | AUC = 0.9808 | Best Threshold = 0.61 | Best F1 = 0.9081\n",
      "[Fold 5] Epoch 5: F1 = 0.9039 | AUC = 0.9810 | Best Threshold = 0.52 | Best F1 = 0.9086\n",
      "[Fold 5] Epoch 6: F1 = 0.8969 | AUC = 0.9790 | Best Threshold = 0.60 | Best F1 = 0.9101\n",
      "[Fold 5] Epoch 7: F1 = 0.8941 | AUC = 0.9747 | Best Threshold = 0.52 | Best F1 = 0.9034\n",
      "[Fold 5] Epoch 8: F1 = 0.8827 | AUC = 0.9724 | Best Threshold = 0.54 | Best F1 = 0.8930\n",
      "[Fold 5] Epoch 9: F1 = 0.9045 | AUC = 0.9763 | Best Threshold = 0.49 | Best F1 = 0.9045\n",
      "[Fold 5] Epoch 10: F1 = 0.8918 | AUC = 0.9754 | Best Threshold = 0.53 | Best F1 = 0.9077\n",
      "[Fold 5] Epoch 11: F1 = 0.9034 | AUC = 0.9740 | Best Threshold = 0.70 | Best F1 = 0.9041\n",
      "\n",
      "Fold 6\n",
      "[Fold 6] Epoch 1: F1 = 0.8976 | AUC = 0.9845 | Best Threshold = 0.67 | Best F1 = 0.9199\n",
      "[Fold 6] Epoch 2: F1 = 0.9257 | AUC = 0.9876 | Best Threshold = 0.52 | Best F1 = 0.9303\n",
      "[Fold 6] Epoch 3: F1 = 0.9326 | AUC = 0.9869 | Best Threshold = 0.37 | Best F1 = 0.9394\n",
      "[Fold 6] Epoch 4: F1 = 0.9347 | AUC = 0.9884 | Best Threshold = 0.67 | Best F1 = 0.9378\n",
      "[Fold 6] Epoch 5: F1 = 0.9340 | AUC = 0.9871 | Best Threshold = 0.66 | Best F1 = 0.9403\n",
      "[Fold 6] Epoch 6: F1 = 0.9278 | AUC = 0.9852 | Best Threshold = 0.38 | Best F1 = 0.9313\n",
      "[Fold 6] Epoch 7: F1 = 0.9270 | AUC = 0.9840 | Best Threshold = 0.53 | Best F1 = 0.9316\n",
      "[Fold 6] Epoch 8: F1 = 0.9177 | AUC = 0.9868 | Best Threshold = 0.70 | Best F1 = 0.9333\n",
      "[Fold 6] Epoch 9: F1 = 0.9223 | AUC = 0.9876 | Best Threshold = 0.18 | Best F1 = 0.9330\n",
      "[Fold 6] Epoch 10: F1 = 0.9137 | AUC = 0.9858 | Best Threshold = 0.65 | Best F1 = 0.9243\n",
      "[Fold 6] Epoch 11: F1 = 0.9326 | AUC = 0.9878 | Best Threshold = 0.55 | Best F1 = 0.9347\n",
      "[Fold 6] Epoch 12: F1 = 0.9027 | AUC = 0.9841 | Best Threshold = 0.73 | Best F1 = 0.9223\n",
      "[Fold 6] Epoch 13: F1 = 0.9100 | AUC = 0.9868 | Best Threshold = 0.32 | Best F1 = 0.9280\n",
      "[Fold 6] Epoch 14: F1 = 0.9295 | AUC = 0.9878 | Best Threshold = 0.59 | Best F1 = 0.9316\n",
      "\n",
      "Fold 7\n",
      "[Fold 7] Epoch 1: F1 = 0.8544 | AUC = 0.9712 | Best Threshold = 0.77 | Best F1 = 0.8833\n",
      "[Fold 7] Epoch 2: F1 = 0.8844 | AUC = 0.9741 | Best Threshold = 0.55 | Best F1 = 0.8900\n",
      "[Fold 7] Epoch 3: F1 = 0.8878 | AUC = 0.9780 | Best Threshold = 0.69 | Best F1 = 0.9057\n",
      "[Fold 7] Epoch 4: F1 = 0.8929 | AUC = 0.9753 | Best Threshold = 0.47 | Best F1 = 0.8939\n",
      "[Fold 7] Epoch 5: F1 = 0.8951 | AUC = 0.9806 | Best Threshold = 0.40 | Best F1 = 0.9046\n",
      "[Fold 7] Epoch 6: F1 = 0.8775 | AUC = 0.9796 | Best Threshold = 0.81 | Best F1 = 0.9032\n",
      "[Fold 7] Epoch 7: F1 = 0.8696 | AUC = 0.9753 | Best Threshold = 0.38 | Best F1 = 0.8958\n",
      "[Fold 7] Epoch 8: F1 = 0.8883 | AUC = 0.9767 | Best Threshold = 0.40 | Best F1 = 0.8935\n",
      "[Fold 7] Epoch 9: F1 = 0.8895 | AUC = 0.9760 | Best Threshold = 0.31 | Best F1 = 0.8978\n",
      "[Fold 7] Epoch 10: F1 = 0.8900 | AUC = 0.9789 | Best Threshold = 0.57 | Best F1 = 0.9000\n",
      "[Fold 7] Epoch 11: F1 = 0.8906 | AUC = 0.9802 | Best Threshold = 0.64 | Best F1 = 0.9077\n",
      "[Fold 7] Epoch 12: F1 = 0.8841 | AUC = 0.9801 | Best Threshold = 0.41 | Best F1 = 0.9029\n",
      "[Fold 7] Epoch 13: F1 = 0.8953 | AUC = 0.9795 | Best Threshold = 0.41 | Best F1 = 0.9016\n",
      "[Fold 7] Epoch 14: F1 = 0.8824 | AUC = 0.9774 | Best Threshold = 0.41 | Best F1 = 0.8969\n",
      "[Fold 7] Epoch 15: F1 = 0.8941 | AUC = 0.9789 | Best Threshold = 0.56 | Best F1 = 0.9048\n",
      "[Fold 7] Epoch 16: F1 = 0.8901 | AUC = 0.9774 | Best Threshold = 0.49 | Best F1 = 0.8989\n",
      "[Fold 7] Epoch 17: F1 = 0.8766 | AUC = 0.9753 | Best Threshold = 0.55 | Best F1 = 0.8853\n",
      "[Fold 7] Epoch 18: F1 = 0.8703 | AUC = 0.9764 | Best Threshold = 0.41 | Best F1 = 0.8901\n",
      "[Fold 7] Epoch 19: F1 = 0.8901 | AUC = 0.9772 | Best Threshold = 0.55 | Best F1 = 0.8971\n",
      "[Fold 7] Epoch 20: F1 = 0.8936 | AUC = 0.9769 | Best Threshold = 0.54 | Best F1 = 0.8984\n",
      "\n",
      "Fold 8\n",
      "[Fold 8] Epoch 1: F1 = 0.8889 | AUC = 0.9790 | Best Threshold = 0.67 | Best F1 = 0.9003\n",
      "[Fold 8] Epoch 2: F1 = 0.9010 | AUC = 0.9810 | Best Threshold = 0.55 | Best F1 = 0.9073\n",
      "[Fold 8] Epoch 3: F1 = 0.8861 | AUC = 0.9805 | Best Threshold = 0.73 | Best F1 = 0.9022\n",
      "[Fold 8] Epoch 4: F1 = 0.9086 | AUC = 0.9830 | Best Threshold = 0.51 | Best F1 = 0.9110\n",
      "[Fold 8] Epoch 5: F1 = 0.8951 | AUC = 0.9793 | Best Threshold = 0.62 | Best F1 = 0.9005\n",
      "[Fold 8] Epoch 6: F1 = 0.8900 | AUC = 0.9754 | Best Threshold = 0.58 | Best F1 = 0.8987\n",
      "[Fold 8] Epoch 7: F1 = 0.8776 | AUC = 0.9742 | Best Threshold = 0.58 | Best F1 = 0.8883\n",
      "[Fold 8] Epoch 8: F1 = 0.9016 | AUC = 0.9820 | Best Threshold = 0.26 | Best F1 = 0.9037\n",
      "[Fold 8] Epoch 9: F1 = 0.9024 | AUC = 0.9818 | Best Threshold = 0.46 | Best F1 = 0.9067\n",
      "[Fold 8] Epoch 10: F1 = 0.8906 | AUC = 0.9816 | Best Threshold = 0.42 | Best F1 = 0.9059\n",
      "[Fold 8] Epoch 11: F1 = 0.8992 | AUC = 0.9798 | Best Threshold = 0.44 | Best F1 = 0.9086\n",
      "[Fold 8] Epoch 12: F1 = 0.9016 | AUC = 0.9796 | Best Threshold = 0.46 | Best F1 = 0.9016\n",
      "[Fold 8] Epoch 13: F1 = 0.9067 | AUC = 0.9814 | Best Threshold = 0.46 | Best F1 = 0.9072\n",
      "\n",
      "Fold 9\n",
      "[Fold 9] Epoch 1: F1 = 0.8949 | AUC = 0.9795 | Best Threshold = 0.67 | Best F1 = 0.9125\n",
      "[Fold 9] Epoch 2: F1 = 0.9118 | AUC = 0.9806 | Best Threshold = 0.55 | Best F1 = 0.9152\n",
      "[Fold 9] Epoch 3: F1 = 0.9171 | AUC = 0.9776 | Best Threshold = 0.49 | Best F1 = 0.9175\n",
      "[Fold 9] Epoch 4: F1 = 0.9227 | AUC = 0.9812 | Best Threshold = 0.51 | Best F1 = 0.9275\n",
      "[Fold 9] Epoch 5: F1 = 0.9153 | AUC = 0.9804 | Best Threshold = 0.53 | Best F1 = 0.9194\n",
      "[Fold 9] Epoch 6: F1 = 0.9091 | AUC = 0.9797 | Best Threshold = 0.56 | Best F1 = 0.9140\n",
      "[Fold 9] Epoch 7: F1 = 0.9149 | AUC = 0.9809 | Best Threshold = 0.48 | Best F1 = 0.9235\n",
      "[Fold 9] Epoch 8: F1 = 0.8889 | AUC = 0.9727 | Best Threshold = 0.38 | Best F1 = 0.9048\n",
      "[Fold 9] Epoch 9: F1 = 0.8889 | AUC = 0.9793 | Best Threshold = 0.64 | Best F1 = 0.9110\n",
      "[Fold 9] Epoch 10: F1 = 0.8958 | AUC = 0.9775 | Best Threshold = 0.62 | Best F1 = 0.8976\n",
      "[Fold 9] Epoch 11: F1 = 0.8947 | AUC = 0.9793 | Best Threshold = 0.37 | Best F1 = 0.9100\n",
      "[Fold 9] Epoch 12: F1 = 0.9029 | AUC = 0.9796 | Best Threshold = 0.69 | Best F1 = 0.9091\n",
      "[Fold 9] Epoch 13: F1 = 0.8969 | AUC = 0.9803 | Best Threshold = 0.57 | Best F1 = 0.9086\n",
      "\n",
      "Fold 10\n",
      "[Fold 10] Epoch 1: F1 = 0.8673 | AUC = 0.9788 | Best Threshold = 0.74 | Best F1 = 0.9029\n",
      "[Fold 10] Epoch 2: F1 = 0.8750 | AUC = 0.9747 | Best Threshold = 0.65 | Best F1 = 0.8941\n",
      "[Fold 10] Epoch 3: F1 = 0.8717 | AUC = 0.9802 | Best Threshold = 0.74 | Best F1 = 0.9044\n",
      "[Fold 10] Epoch 4: F1 = 0.8708 | AUC = 0.9745 | Best Threshold = 0.75 | Best F1 = 0.8974\n",
      "[Fold 10] Epoch 5: F1 = 0.8883 | AUC = 0.9812 | Best Threshold = 0.63 | Best F1 = 0.9207\n",
      "[Fold 10] Epoch 6: F1 = 0.8861 | AUC = 0.9771 | Best Threshold = 0.80 | Best F1 = 0.9072\n",
      "[Fold 10] Epoch 7: F1 = 0.9027 | AUC = 0.9813 | Best Threshold = 0.64 | Best F1 = 0.9203\n",
      "[Fold 10] Epoch 8: F1 = 0.8945 | AUC = 0.9773 | Best Threshold = 0.57 | Best F1 = 0.9031\n",
      "[Fold 10] Epoch 9: F1 = 0.8768 | AUC = 0.9795 | Best Threshold = 0.83 | Best F1 = 0.9091\n",
      "[Fold 10] Epoch 10: F1 = 0.8916 | AUC = 0.9781 | Best Threshold = 0.78 | Best F1 = 0.9124\n",
      "[Fold 10] Epoch 11: F1 = 0.8955 | AUC = 0.9790 | Best Threshold = 0.70 | Best F1 = 0.9008\n",
      "[Fold 10] Epoch 12: F1 = 0.9036 | AUC = 0.9766 | Best Threshold = 0.59 | Best F1 = 0.9077\n",
      "[Fold 10] Epoch 13: F1 = 0.8747 | AUC = 0.9794 | Best Threshold = 0.86 | Best F1 = 0.9115\n",
      "[Fold 10] Epoch 14: F1 = 0.9023 | AUC = 0.9789 | Best Threshold = 0.90 | Best F1 = 0.9169\n"
     ]
    }
   ],
   "source": [
    "best_thresholds = []\n",
    "val_probs_all = []\n",
    "val_targets_all = []\n",
    "\n",
    "for fold_id, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nFold {fold_id + 1}\")\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = FusionNetGIT2(input_dim=X.shape[1]).to(DEVICE)\n",
    "    best_t, val_probs, val_targets = train_fold(model, train_loader, val_loader, fold_id + 1)\n",
    "    best_thresholds.append(best_t)\n",
    "    val_probs_all.extend(val_probs)\n",
    "    val_targets_all.extend(val_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:52.456868Z",
     "iopub.status.busy": "2025-06-28T06:54:52.456668Z",
     "iopub.status.idle": "2025-06-28T06:54:52.640971Z",
     "shell.execute_reply": "2025-06-28T06:54:52.640117Z",
     "shell.execute_reply.started": "2025-06-28T06:54:52.456852Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Threshold: 0.5100 | Global F1: 0.9029\n"
     ]
    }
   ],
   "source": [
    "val_probs_all = np.array(val_probs_all)\n",
    "val_targets_all = np.array(val_targets_all)\n",
    "\n",
    "def find_best_threshold(y_true, y_probs):\n",
    "    thresholds = np.arange(0.1, 0.91, 0.01)\n",
    "    best_t, best_f1 = 0.5, 0.0\n",
    "    for t in thresholds:\n",
    "        preds = (y_probs >= t).astype(int)\n",
    "        f1 = f1_score(y_true, preds, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_t, best_f1 = t, f1\n",
    "    return best_t, best_f1\n",
    "\n",
    "global_thresh, global_f1 = find_best_threshold(val_targets_all, val_probs_all)\n",
    "\n",
    "print(f\"\\nGlobal Threshold: {global_thresh:.4f} | Global F1: {global_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:52.642014Z",
     "iopub.status.busy": "2025-06-28T06:54:52.641765Z",
     "iopub.status.idle": "2025-06-28T06:54:52.646655Z",
     "shell.execute_reply": "2025-06-28T06:54:52.645775Z",
     "shell.execute_reply.started": "2025-06-28T06:54:52.641968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.5699999999999997), np.float64(0.46999999999999986), np.float64(0.4299999999999998), np.float64(0.7299999999999996), np.float64(0.7199999999999996), np.float64(0.6599999999999997), np.float64(0.6399999999999997), np.float64(0.5099999999999998), np.float64(0.5099999999999998), np.float64(0.6299999999999997)]\n"
     ]
    }
   ],
   "source": [
    "print(best_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:52.647668Z",
     "iopub.status.busy": "2025-06-28T06:54:52.647448Z",
     "iopub.status.idle": "2025-06-28T06:54:52.661411Z",
     "shell.execute_reply": "2025-06-28T06:54:52.660724Z",
     "shell.execute_reply.started": "2025-06-28T06:54:52.647653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5869999999999999\n"
     ]
    }
   ],
   "source": [
    "cleaned_thresh = [i for i in best_thresholds if 0.4<=i<=0.8]\n",
    "thresh2 = np.mean(best_thresholds)\n",
    "print(thresh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:52.662483Z",
     "iopub.status.busy": "2025-06-28T06:54:52.662237Z",
     "iopub.status.idle": "2025-06-28T06:54:52.830049Z",
     "shell.execute_reply": "2025-06-28T06:54:52.829231Z",
     "shell.execute_reply.started": "2025-06-28T06:54:52.662462Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3483809003</td>\n",
       "      <td>Title: flooded parking lot at emily fowler lib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3712805295</td>\n",
       "      <td>Title: larc de barà the roman arch of barà | D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>379845620</td>\n",
       "      <td>Title: highest point over the sea level that i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7343264988</td>\n",
       "      <td>Title: lagos after the rains | Description: af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3843337492</td>\n",
       "      <td>Title: flooded corley ave | Description: also ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "0  3483809003  Title: flooded parking lot at emily fowler lib...\n",
       "1  3712805295  Title: larc de barà the roman arch of barà | D...\n",
       "2   379845620  Title: highest point over the sea level that i...\n",
       "3  7343264988  Title: lagos after the rains | Description: af...\n",
       "4  3843337492  Title: flooded corley ave | Description: also ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# --- Đọc dữ liệu ---\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# --- Làm sạch ID ---\n",
    "test_df['id'] = test_df['id'].apply(lambda x: int(float(x)) if pd.notnull(x) else x)\n",
    "\n",
    "# --- Hàm chuyển user_tags từ chuỗi → list an toàn ---\n",
    "def safe_list(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            val = ast.literal_eval(x)\n",
    "            if isinstance(val, list):\n",
    "                return val\n",
    "        except Exception:\n",
    "            pass\n",
    "        return [x] if x else []\n",
    "    return []\n",
    "\n",
    "test_df[\"user_tags\"] = test_df[\"user_tags\"].apply(safe_list)\n",
    "\n",
    "# --- Hàm làm sạch từng cột text ---\n",
    "def basic_clean(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = unicodedata.normalize('NFKC', text)  # Chuẩn Unicode\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # Bỏ URL\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"\", text)  # Bỏ email\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)  # Bỏ HTML tags\n",
    "    text = re.sub(r\"[^\\w\\s\\u4e00-\\u9fff\\u3040-\\u30ff\\uac00-\\ud7af\\-_#]+\", \"\", text)  # Giữ emoji + đa ngôn ngữ\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Rút gọn khoảng trắng\n",
    "    return text.lower().strip()\n",
    "\n",
    "# --- Làm sạch từng trường ---\n",
    "test_df[\"title\"] = test_df[\"title\"].fillna(\"\").astype(str).apply(basic_clean)\n",
    "test_df[\"description\"] = test_df[\"description\"].fillna(\"\").astype(str).apply(basic_clean)\n",
    "test_df[\"user_tags\"] = test_df[\"user_tags\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else str(x))\n",
    "test_df[\"user_tags\"] = test_df[\"user_tags\"].apply(basic_clean)\n",
    "\n",
    "# --- Gộp thành text đầu vào ---\n",
    "test_df[\"text\"] = test_df.apply(\n",
    "    lambda row: f\"Title: {row['title']} | Description: {row['description']} | Tags: {row['user_tags']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ✅ Kết quả\n",
    "test_df[[\"id\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:54:52.831222Z",
     "iopub.status.busy": "2025-06-28T06:54:52.830926Z",
     "iopub.status.idle": "2025-06-28T06:55:03.479349Z",
     "shell.execute_reply": "2025-06-28T06:55:03.478659Z",
     "shell.execute_reply.started": "2025-06-28T06:54:52.831204Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số ảnh hợp lệ: 1320\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Đường dẫn thư mục chứa ảnh ---\n",
    "IMG_TEST_DIR = \"../data/testset_images/testset_images\"\n",
    "\n",
    "# --- Đuôi ảnh hợp lệ ---\n",
    "valid_exts = [\".jpg\", \".png\"]\n",
    "\n",
    "# --- Lọc danh sách file ảnh ---\n",
    "image_files = [\n",
    "    f for f in os.listdir(IMG_TEST_DIR)\n",
    "    if os.path.isfile(os.path.join(IMG_TEST_DIR, f))\n",
    "    and not f.startswith(\"._\")\n",
    "    and os.path.splitext(f.lower())[1] in valid_exts\n",
    "]\n",
    "print(f\"Tổng số ảnh hợp lệ: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:55:03.480891Z",
     "iopub.status.busy": "2025-06-28T06:55:03.480129Z",
     "iopub.status.idle": "2025-06-28T06:55:03.484676Z",
     "shell.execute_reply": "2025-06-28T06:55:03.484033Z",
     "shell.execute_reply.started": "2025-06-28T06:55:03.480864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_image_path_test(image_id, exts=[\".jpg\", \".png\"]):\n",
    "    for ext in exts:\n",
    "        path = os.path.join(IMG_TEST_DIR, f\"{image_id}{ext}\")\n",
    "        if os.path.isfile(path):\n",
    "            return path\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:55:03.485631Z",
     "iopub.status.busy": "2025-06-28T06:55:03.485356Z",
     "iopub.status.idle": "2025-06-28T06:56:35.860390Z",
     "shell.execute_reply": "2025-06-28T06:56:35.859689Z",
     "shell.execute_reply.started": "2025-06-28T06:55:03.485600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting GIT-2 test features: 100%|██████████| 1320/1320 [02:17<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu git2_features_test.npy\n",
      "Shape: (1320, 768)\n",
      "Số lượng lỗi: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "expected_shape = (768,)\n",
    "all_features = []\n",
    "error_count = 0\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Extracting GIT-2 test features\"):\n",
    "    try:\n",
    "        image_id = str(int(row[\"id\"]))\n",
    "        image_path = find_image_path_test(image_id)\n",
    "        text_input = row[\"text\"]\n",
    "\n",
    "        if image_path is not None:\n",
    "            feat = extract_git2_feature(image_path, text_input, fallback_dim=expected_shape[0])\n",
    "        else:\n",
    "            print(f\"Missing image: {image_id}\")\n",
    "            feat = np.zeros(expected_shape, dtype=np.float32)\n",
    "\n",
    "        if feat.shape != expected_shape:\n",
    "            print(f\"Wrong shape for ID {image_id}\")\n",
    "            feat = np.zeros(expected_shape, dtype=np.float32)\n",
    "\n",
    "        all_features.append(feat)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at idx {idx}, id {row['id']}: {e}\")\n",
    "        all_features.append(np.zeros(expected_shape, dtype=np.float32))\n",
    "        error_count += 1\n",
    "\n",
    "# --- Save ra file .npy ---\n",
    "all_features = np.stack(all_features)\n",
    "np.save(\"git2_features_test.npy\", all_features)\n",
    "print(\"Đã lưu git2_features_test.npy\")\n",
    "print(f\"Shape: {all_features.shape}\")\n",
    "print(f\"Số lượng lỗi: {error_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:56:35.861372Z",
     "iopub.status.busy": "2025-06-28T06:56:35.861107Z",
     "iopub.status.idle": "2025-06-28T06:56:36.025349Z",
     "shell.execute_reply": "2025-06-28T06:56:36.024796Z",
     "shell.execute_reply.started": "2025-06-28T06:56:35.861341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with Fold 1\n",
      "Predicting with Fold 2\n",
      "Predicting with Fold 3\n",
      "Predicting with Fold 4\n",
      "Predicting with Fold 5\n",
      "Predicting with Fold 6\n",
      "Predicting with Fold 7\n",
      "Predicting with Fold 8\n",
      "Predicting with Fold 9\n",
      "Predicting with Fold 10\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Nạp đặc trưng test ---\n",
    "git2_test = np.load(\"git2_features_test.npy\")  # shape: (M, 768)\n",
    "X_test_tensor = torch.tensor(git2_test, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# --- 2. Dự đoán theo từng fold ---\n",
    "NUM_FOLDS = 10\n",
    "all_probs = []\n",
    "\n",
    "for fold in range(1, NUM_FOLDS + 1):\n",
    "    print(f\"Predicting with Fold {fold}\")\n",
    "    \n",
    "    model = FusionNetGIT2(input_dim=768).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(f\"best_model_fold{fold}.pt\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_test_tensor)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy().flatten()  # xác suất\n",
    "        all_probs.append(probs)\n",
    "\n",
    "# --- 3. Trung bình xác suất giữa các fold ---\n",
    "ensemble_probs = np.mean(all_probs, axis=0)\n",
    "ensemble_preds = (ensemble_probs >= thresh2).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:56:36.028174Z",
     "iopub.status.busy": "2025-06-28T06:56:36.027957Z",
     "iopub.status.idle": "2025-06-28T06:56:36.033233Z",
     "shell.execute_reply": "2025-06-28T06:56:36.032529Z",
     "shell.execute_reply.started": "2025-06-28T06:56:36.028158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_df = test_df.copy()  # test_df phải có cột 'id'\n",
    "results_df[\"label\"] = ensemble_preds\n",
    "results_df[\"probability\"] = ensemble_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:56:36.082771Z",
     "iopub.status.busy": "2025-06-28T06:56:36.082487Z",
     "iopub.status.idle": "2025-06-28T06:56:36.092576Z",
     "shell.execute_reply": "2025-06-28T06:56:36.091930Z",
     "shell.execute_reply.started": "2025-06-28T06:56:36.082746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_df = results_df[[\"id\", \"label\", \"probability\"]].copy()\n",
    "results_df.sort_values(by=\"probability\", ascending=False, inplace=True)\n",
    "results_df.to_csv(\"../create_output/result_git2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T06:56:36.109326Z",
     "iopub.status.busy": "2025-06-28T06:56:36.109076Z",
     "iopub.status.idle": "2025-06-28T06:56:36.120046Z",
     "shell.execute_reply": "2025-06-28T06:56:36.119457Z",
     "shell.execute_reply.started": "2025-06-28T06:56:36.109304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Số lượng dự đoán là 1: 469\n"
     ]
    }
   ],
   "source": [
    "num_positives = (results_df[\"label\"] == 1).sum()\n",
    "print(f\"📊 Số lượng dự đoán là 1: {num_positives}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12423451,
     "sourceId": 103210,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
