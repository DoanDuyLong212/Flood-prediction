{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d9a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # Nếu dùng GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb85af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from timm import create_model\n",
    "import json\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d32d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\timm\\models\\_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b7_ns to current tf_efficientnet_b7.ns_jft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNormAct2d(\n",
       "    64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(288, 288, kernel_size=(5, 5), stride=(2, 2), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(480, 480, kernel_size=(3, 3), stride=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(1344, 1344, kernel_size=(5, 5), stride=(2, 2), groups=1344, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNormAct2d(\n",
       "    2560, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b7_model = create_model('tf_efficientnet_b7_ns', pretrained=True, num_classes=0).to(DEVICE)\n",
    "b7_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34c31b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2Model(\n",
       "  (embeddings): DebertaV2Embeddings(\n",
       "    (word_embeddings): Embedding(251000, 768, padding_idx=0)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): DebertaV2Encoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rel_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/mdeberta-v3-base')\n",
    "deberta_model = AutoModel.from_pretrained('microsoft/mdeberta-v3-base').to(DEVICE)\n",
    "deberta_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4e444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing ảnh ---\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((600, 600)),\n",
    "    transforms.RandomResizedCrop(600, scale=(0.9, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.RandomRotation(degrees=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8e346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_b7_features(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image_transform(image).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            features = b7_model(image).squeeze(0)\n",
    "        return features.cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Lỗi ảnh tại {image_path}: {e}\")\n",
    "        return np.zeros(2560, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda39949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_deberta_features(text):\n",
    "    try:\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            outputs = deberta_model(**inputs)\n",
    "        last_hidden = outputs.last_hidden_state  # (1, seq_len, 768)\n",
    "        features = last_hidden.mean(dim=1).squeeze(0).cpu().numpy()  # (768,)\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Lỗi DeBERTa với text: {text} - {e}\")\n",
    "        return np.zeros(768, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3896026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>user_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3519864665</td>\n",
       "      <td>Biltmore Estate</td>\n",
       "      <td>None</td>\n",
       "      <td>[2009 road trip, obrero road trip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896119055</td>\n",
       "      <td>Chand Minar</td>\n",
       "      <td>None</td>\n",
       "      <td>[daulatabad, daulatabad fort, ellora, road trip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3468473862</td>\n",
       "      <td>Uplifting Graffiti</td>\n",
       "      <td>After the flood, the boarded up stores bear up...</td>\n",
       "      <td>[cedarrapids, createsouthroadtrip2009, disaste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4120853942</td>\n",
       "      <td>DSCF6487</td>\n",
       "      <td>None</td>\n",
       "      <td>[cork, enchente, flood, ireland, irlanda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4436083254</td>\n",
       "      <td>Oconoe river - flooded</td>\n",
       "      <td>None</td>\n",
       "      <td>[athens georgia, brown, current, flood, mud, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>8119782888</td>\n",
       "      <td>90</td>\n",
       "      <td>None</td>\n",
       "      <td>[550d, camino, canon, canoneos550d, canoneoski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>6093294301</td>\n",
       "      <td>Albany's Corning Preserve, day after Irene</td>\n",
       "      <td>None</td>\n",
       "      <td>[albany, ny, flood, walk, water]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>6791185487</td>\n",
       "      <td>IMG_4989</td>\n",
       "      <td>None</td>\n",
       "      <td>[al, the waters in pike road]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>9144682941</td>\n",
       "      <td>IMG_3011</td>\n",
       "      <td>2013 Fair Flood</td>\n",
       "      <td>[2013, county, fair, flood, linn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>596012254</td>\n",
       "      <td>Prison building</td>\n",
       "      <td>Alcatraz trip, San Francisco</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                       title  \\\n",
       "0     3519864665                             Biltmore Estate   \n",
       "1     4896119055                                 Chand Minar   \n",
       "2     3468473862                          Uplifting Graffiti   \n",
       "3     4120853942                                    DSCF6487   \n",
       "4     4436083254                      Oconoe river - flooded   \n",
       "...          ...                                         ...   \n",
       "5275  8119782888                                          90   \n",
       "5276  6093294301  Albany's Corning Preserve, day after Irene   \n",
       "5277  6791185487                                    IMG_4989   \n",
       "5278  9144682941                                    IMG_3011   \n",
       "5279   596012254                             Prison building   \n",
       "\n",
       "                                            description  \\\n",
       "0                                                  None   \n",
       "1                                                  None   \n",
       "2     After the flood, the boarded up stores bear up...   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "5275                                               None   \n",
       "5276                                               None   \n",
       "5277                                               None   \n",
       "5278                                    2013 Fair Flood   \n",
       "5279                       Alcatraz trip, San Francisco   \n",
       "\n",
       "                                              user_tags  \n",
       "0                    [2009 road trip, obrero road trip]  \n",
       "1      [daulatabad, daulatabad fort, ellora, road trip]  \n",
       "2     [cedarrapids, createsouthroadtrip2009, disaste...  \n",
       "3             [cork, enchente, flood, ireland, irlanda]  \n",
       "4     [athens georgia, brown, current, flood, mud, r...  \n",
       "...                                                 ...  \n",
       "5275  [550d, camino, canon, canoneos550d, canoneoski...  \n",
       "5276                   [albany, ny, flood, walk, water]  \n",
       "5277                      [al, the waters in pike road]  \n",
       "5278                  [2013, county, fair, flood, linn]  \n",
       "5279                                                 []  \n",
       "\n",
       "[5280 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/devset_images_metadata.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "train_data = json_data['images']\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "cols_needed = ['image_id', 'title', 'description', 'user_tags']\n",
    "available_cols = [col for col in cols_needed if col in train_df.columns]\n",
    "train_df = train_df[available_cols].rename(columns={'image_id': 'id'})\n",
    "\n",
    "train_df['id'] = train_df['id'].astype(int)\n",
    "train_df.to_csv(\"../data/devset_images_metadata.csv\", index=False)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "422e86ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3519864665</td>\n",
       "      <td>Title: biltmore estate | Description:  | Tags:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896119055</td>\n",
       "      <td>Title: chand minar | Description:  | Tags: dau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3468473862</td>\n",
       "      <td>Title: uplifting graffiti | Description: after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4120853942</td>\n",
       "      <td>Title: dscf6487 | Description:  | Tags: cork e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4436083254</td>\n",
       "      <td>Title: oconoe river - flooded | Description:  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  label\n",
       "0  3519864665  Title: biltmore estate | Description:  | Tags:...      0\n",
       "1  4896119055  Title: chand minar | Description:  | Tags: dau...      0\n",
       "2  3468473862  Title: uplifting graffiti | Description: after...      0\n",
       "3  4120853942  Title: dscf6487 | Description:  | Tags: cork e...      0\n",
       "4  4436083254  Title: oconoe river - flooded | Description:  ...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# --- Đường dẫn ---\n",
    "IMG_DIR = os.path.join(\"../data/devset_images\", \"devset_images\")\n",
    "FEAT_DIR = os.path.join(\"../data/devset_images_features\", \"devset_images_features\")\n",
    "META_CSV = os.path.join(\"../data/devset_images_metadata.csv\")\n",
    "GT_CSV = os.path.join(\"../data/devset_images_gt.csv\")\n",
    "\n",
    "# --- Load dữ liệu ---\n",
    "train_df = pd.read_csv(META_CSV)\n",
    "label_df = pd.read_csv(GT_CSV)\n",
    "\n",
    "# --- Làm sạch ID ---\n",
    "train_df['id'] = train_df['id'].apply(lambda x: int(float(x)) if pd.notnull(x) else x)\n",
    "label_df['id'] = label_df['id'].apply(lambda x: int(float(x)) if pd.notnull(x) else x)\n",
    "\n",
    "# --- Chuyển user_tags từ chuỗi → list an toàn ---\n",
    "def safe_list(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            val = ast.literal_eval(x)\n",
    "            if isinstance(val, list):\n",
    "                return val\n",
    "        except Exception:\n",
    "            pass\n",
    "        return [x] if x else []\n",
    "    return []\n",
    "\n",
    "train_df[\"user_tags\"] = train_df[\"user_tags\"].apply(safe_list)\n",
    "\n",
    "# --- Làm sạch từng cột cơ bản ---\n",
    "def basic_clean(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = unicodedata.normalize('NFKC', text)                       # Chuẩn Unicode\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)              # Bỏ URL\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"\", text)                              # Bỏ email\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)                                # Bỏ HTML tags\n",
    "    text = re.sub(r\"[^\\w\\s\\u4e00-\\u9fff\\u3040-\\u30ff\\uac00-\\ud7af\\-_#]+\", \"\", text)  # Giữ emoji + đa ngôn ngữ\n",
    "    text = re.sub(r\"\\s+\", \" \", text)                                 # Rút gọn khoảng trắng\n",
    "    return text.lower().strip()  \n",
    "\n",
    "train_df[\"title\"] = train_df[\"title\"].fillna(\"\").astype(str).apply(basic_clean)\n",
    "train_df[\"description\"] = train_df[\"description\"].fillna(\"\").astype(str).apply(basic_clean)\n",
    "train_df[\"user_tags\"] = train_df[\"user_tags\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else str(x))\n",
    "train_df[\"user_tags\"] = train_df[\"user_tags\"].apply(basic_clean)\n",
    "\n",
    "# --- Gộp thành text cho BLIP (không clean lại nữa) ---\n",
    "train_df[\"text\"] = train_df.apply(\n",
    "    lambda row: f\"Title: {row['title']} | Description: {row['description']} | Tags: {row['user_tags']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- Gộp với label ---\n",
    "train_df = train_df.merge(label_df, on=\"id\", how=\"left\")\n",
    "\n",
    "# ✅ Kết quả\n",
    "train_df[[\"id\", \"text\", \"label\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e052e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_path(image_id, exts=[\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\" ]):\n",
    "    for ext in exts:\n",
    "        path = os.path.join(IMG_DIR, f\"{image_id}{ext}\")\n",
    "        if os.path.isfile(path):\n",
    "            return path\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "973c898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ Tổng số ảnh hợp lệ (không bắt đầu bằng '._'): 5280\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Các đuôi ảnh hợp lệ\n",
    "valid_exts = [\".jpg\", \".png\",  \".gif\"]\n",
    "\n",
    "# Lọc file ảnh hợp lệ\n",
    "image_files = [\n",
    "    f for f in os.listdir(IMG_DIR)\n",
    "    if os.path.isfile(os.path.join(IMG_DIR, f))\n",
    "    and not f.startswith(\"._\")\n",
    "    and os.path.splitext(f.lower())[1] in valid_exts\n",
    "]\n",
    "\n",
    "# In kết quả\n",
    "print(f\"🖼️ Tổng số ảnh hợp lệ (không bắt đầu bằng '._'): {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fbe32da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 5280/5280 [10:11<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu b7_deberta_features.npy và b7_deberta_labels.npy\n",
      "Shape features: (5280, 3328), labels: (5280,)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Extracting features\"):\n",
    "    image_id = str(int(row[\"id\"]))\n",
    "    image_path = find_image_path(image_id)\n",
    "\n",
    "    # Mặc định là zero vector nếu lỗi\n",
    "    image_feat = np.zeros(2560, dtype=np.float32)\n",
    "    text_feat = np.zeros(768, dtype=np.float32)\n",
    "\n",
    "    # Trích xuất đặc trưng ảnh nếu có ảnh\n",
    "    if image_path:\n",
    "        image_feat = extract_b7_features(image_path)\n",
    "    else:\n",
    "        print(f\"Không tìm thấy ảnh cho id {image_id}\")\n",
    "\n",
    "    # Trích xuất đặc trưng văn bản\n",
    "    if isinstance(row[\"text\"], str):\n",
    "        text_feat = extract_deberta_features(row[\"text\"])\n",
    "\n",
    "    # Gộp lại\n",
    "    combined_feat = np.concatenate([image_feat, text_feat])\n",
    "    all_features.append(combined_feat)\n",
    "    all_labels.append(row[\"label\"])\n",
    "\n",
    "# Convert sang mảng numpy\n",
    "all_features = np.stack(all_features)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Lưu đặc trưng và nhãn\n",
    "np.save(\"b7_deberta_features.npy\", all_features)\n",
    "np.save(\"b7_deberta_labels.npy\", all_labels)\n",
    "\n",
    "print(\"Đã lưu b7_deberta_features.npy và b7_deberta_labels.npy\")\n",
    "print(f\"Shape features: {all_features.shape}, labels: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c5ffea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
    "# import numpy as np\n",
    "\n",
    "# # 🔶 Focal Loss định nghĩa sẵn (cho binary classification)\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.reduction = reduction\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "#         probs = torch.sigmoid(inputs)\n",
    "#         pt = torch.where(targets == 1, probs, 1 - probs)\n",
    "#         focal_weight = self.alpha * (1 - pt) ** self.gamma\n",
    "#         loss = focal_weight * BCE_loss\n",
    "\n",
    "#         if self.reduction == 'mean':\n",
    "#             return loss.mean()\n",
    "#         elif self.reduction == 'sum':\n",
    "#             return loss.sum()\n",
    "#         else:\n",
    "#             return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86228691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "024c4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"b7_deberta_features.npy\")           # (N, 3328)\n",
    "y = np.load(\"b7_deberta_labels.npy\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d1dfcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # (N, 1)\n",
    "dataset = TensorDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87d6c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e65aafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = torch.tensor(3360 / 1920, dtype=torch.float32).to(DEVICE)  # = 1.75\n",
    "# pos_weight = torch.tensor(3360 / 1680, dtype=torch.float32).to(DEVICE)  # = 2\n",
    "# pos_weight = torch.tensor(3360 / 2240, dtype=torch.float32).to(DEVICE)  # = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84917ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def train_fold(model, train_loader, val_loader, fold_id, total_epochs=50, lr_max=0.00068):\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    # criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr_max, weight_decay=0.001)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3, min_lr=1e-7\n",
    "    )\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    #     optimizer, T_max=total_epochs, eta_min=1e-7\n",
    "    # )\n",
    "\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_threshold = 0.5  # sẽ được cập nhật sau\n",
    "    patience = 9\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_probs, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                preds = model(xb)\n",
    "                loss = criterion(preds, yb)\n",
    "                val_loss += loss.item()\n",
    "                probs = torch.sigmoid(preds).cpu().numpy().flatten()\n",
    "                all_probs.extend(probs)\n",
    "                all_targets.extend(yb.cpu().numpy().flatten())\n",
    "\n",
    "        probs = np.array(all_probs)\n",
    "        targets = np.array(all_targets)\n",
    "\n",
    "        # Tìm threshold tối ưu theo F1\n",
    "        def find_best_threshold(y_true, y_prob):\n",
    "            thresholds = np.arange(0.1, 0.91, 0.01)\n",
    "            best_t = 0.5\n",
    "            best_f1_local = 0.0\n",
    "            for t in thresholds:\n",
    "                preds = (y_prob >= t).astype(int)\n",
    "                f1 = f1_score(y_true, preds, zero_division=0)\n",
    "                if f1 > best_f1_local:\n",
    "                    best_f1_local = f1\n",
    "                    best_t = t\n",
    "            return best_t, best_f1_local\n",
    "        \n",
    "        best_threshold_this_epoch, best_f1_this_epoch = find_best_threshold(targets, probs)\n",
    "\n",
    "        # F1 khi dùng threshold mặc định 0.5 (cho thống kê)\n",
    "        preds_bin = (probs >= 0.5).astype(int)\n",
    "        acc = (preds_bin == targets).mean()\n",
    "        auc = roc_auc_score(targets, probs)\n",
    "        precision = precision_score(targets, preds_bin, zero_division=0)\n",
    "        recall = recall_score(targets, preds_bin, zero_division=0)\n",
    "        f1 = f1_score(targets, preds_bin, zero_division=0)\n",
    "\n",
    "        scheduler.step(f1)\n",
    "\n",
    "        print(f\"[Fold {fold_id}] Epoch {epoch+1}: Train Loss = {train_loss:.4f} | \"\n",
    "              f\"Val Loss = {val_loss:.4f} | Acc = {acc:.4f} | AUC = {auc:.4f} | \"\n",
    "              f\"Precision = {precision:.4f} | Recall = {recall:.4f} | F1 = {f1:.4f} | \"\n",
    "              f\"Best Threshold = {best_threshold_this_epoch:.4f} | Best F1 = {best_f1_this_epoch:.4f}\")\n",
    "\n",
    "        # Cập nhật model nếu F1 tốt hơn\n",
    "        if best_f1_this_epoch > best_f1:\n",
    "            best_f1 = best_f1_this_epoch\n",
    "            best_threshold = best_threshold_this_epoch\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_fold{fold_id}.pt\")\n",
    "            print(f\"Fold {fold_id} - New best F1: {best_f1:.4f} at threshold {best_threshold:.4f} → model saved.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Fold {fold_id} - Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    return best_threshold, probs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65693b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionNetPlus(nn.Module):\n",
    "    def __init__(self, input_dim=3328):\n",
    "        super(FusionNetPlus, self).__init__()\n",
    "        self.bn_input = nn.BatchNorm1d(input_dim)\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(384)\n",
    "        self.fc2 = nn.Linear(512, 384)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(384, 128)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.dropout4 = nn.Dropout(0.1)\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn_input(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80b1a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Starting Fold 1\n",
      "[Fold 1] Epoch 1: Train Loss = 15.5552 | Val Loss = 1.5623 | Acc = 0.8939 | AUC = 0.9742 | Precision = 0.7857 | Recall = 0.9740 | F1 = 0.8698 | Best Threshold = 0.7300 | Best F1 = 0.9072\n",
      "Fold 1 - New best F1: 0.9072 at threshold 0.7300 → model saved.\n",
      "[Fold 1] Epoch 2: Train Loss = 9.3121 | Val Loss = 1.1611 | Acc = 0.9261 | AUC = 0.9811 | Precision = 0.8493 | Recall = 0.9688 | F1 = 0.9051 | Best Threshold = 0.5900 | Best F1 = 0.9127\n",
      "Fold 1 - New best F1: 0.9127 at threshold 0.5900 → model saved.\n",
      "[Fold 1] Epoch 3: Train Loss = 6.3376 | Val Loss = 1.0885 | Acc = 0.9375 | AUC = 0.9815 | Precision = 0.8698 | Recall = 0.9740 | F1 = 0.9189 | Best Threshold = 0.5700 | Best F1 = 0.9235\n",
      "Fold 1 - New best F1: 0.9235 at threshold 0.5700 → model saved.\n",
      "[Fold 1] Epoch 4: Train Loss = 5.1274 | Val Loss = 1.0561 | Acc = 0.9242 | AUC = 0.9825 | Precision = 0.8585 | Recall = 0.9479 | F1 = 0.9010 | Best Threshold = 0.7000 | Best F1 = 0.9147\n",
      "[Fold 1] Epoch 5: Train Loss = 3.9146 | Val Loss = 0.9587 | Acc = 0.9356 | AUC = 0.9817 | Precision = 0.8798 | Recall = 0.9531 | F1 = 0.9150 | Best Threshold = 0.6000 | Best F1 = 0.9258\n",
      "Fold 1 - New best F1: 0.9258 at threshold 0.6000 → model saved.\n",
      "[Fold 1] Epoch 6: Train Loss = 3.7646 | Val Loss = 0.9515 | Acc = 0.9413 | AUC = 0.9812 | Precision = 0.8927 | Recall = 0.9531 | F1 = 0.9219 | Best Threshold = 0.4100 | Best F1 = 0.9254\n",
      "[Fold 1] Epoch 7: Train Loss = 3.4979 | Val Loss = 0.9295 | Acc = 0.9451 | AUC = 0.9818 | Precision = 0.8826 | Recall = 0.9792 | F1 = 0.9284 | Best Threshold = 0.3700 | Best F1 = 0.9314\n",
      "Fold 1 - New best F1: 0.9314 at threshold 0.3700 → model saved.\n",
      "[Fold 1] Epoch 8: Train Loss = 2.2473 | Val Loss = 0.9262 | Acc = 0.9508 | AUC = 0.9819 | Precision = 0.8915 | Recall = 0.9844 | F1 = 0.9356 | Best Threshold = 0.6400 | Best F1 = 0.9400\n",
      "Fold 1 - New best F1: 0.9400 at threshold 0.6400 → model saved.\n",
      "[Fold 1] Epoch 9: Train Loss = 1.8947 | Val Loss = 1.1094 | Acc = 0.9299 | AUC = 0.9801 | Precision = 0.8708 | Recall = 0.9479 | F1 = 0.9077 | Best Threshold = 0.3700 | Best F1 = 0.9158\n",
      "[Fold 1] Epoch 10: Train Loss = 1.9779 | Val Loss = 1.1369 | Acc = 0.9356 | AUC = 0.9774 | Precision = 0.8726 | Recall = 0.9635 | F1 = 0.9158 | Best Threshold = 0.5200 | Best F1 = 0.9181\n",
      "[Fold 1] Epoch 11: Train Loss = 1.4894 | Val Loss = 0.8942 | Acc = 0.9451 | AUC = 0.9830 | Precision = 0.8937 | Recall = 0.9635 | F1 = 0.9273 | Best Threshold = 0.5100 | Best F1 = 0.9296\n",
      "[Fold 1] Epoch 12: Train Loss = 1.6331 | Val Loss = 1.1810 | Acc = 0.9299 | AUC = 0.9785 | Precision = 0.8856 | Recall = 0.9271 | F1 = 0.9059 | Best Threshold = 0.2500 | Best F1 = 0.9104\n",
      "[Fold 1] Epoch 13: Train Loss = 1.4479 | Val Loss = 1.0175 | Acc = 0.9318 | AUC = 0.9809 | Precision = 0.8786 | Recall = 0.9427 | F1 = 0.9095 | Best Threshold = 0.7200 | Best F1 = 0.9203\n",
      "[Fold 1] Epoch 14: Train Loss = 0.7478 | Val Loss = 1.0154 | Acc = 0.9337 | AUC = 0.9811 | Precision = 0.8829 | Recall = 0.9427 | F1 = 0.9118 | Best Threshold = 0.3000 | Best F1 = 0.9280\n",
      "[Fold 1] Epoch 15: Train Loss = 0.7793 | Val Loss = 1.0417 | Acc = 0.9356 | AUC = 0.9804 | Precision = 0.8873 | Recall = 0.9427 | F1 = 0.9141 | Best Threshold = 0.2600 | Best F1 = 0.9235\n",
      "[Fold 1] Epoch 16: Train Loss = 0.6990 | Val Loss = 1.1115 | Acc = 0.9394 | AUC = 0.9797 | Precision = 0.8846 | Recall = 0.9583 | F1 = 0.9200 | Best Threshold = 0.4800 | Best F1 = 0.9227\n",
      "[Fold 1] Epoch 17: Train Loss = 0.8434 | Val Loss = 1.0636 | Acc = 0.9356 | AUC = 0.9796 | Precision = 0.8835 | Recall = 0.9479 | F1 = 0.9146 | Best Threshold = 0.3400 | Best F1 = 0.9265\n",
      "Fold 1 - Early stopping at epoch 17\n",
      "\n",
      "📦 Starting Fold 2\n",
      "[Fold 2] Epoch 1: Train Loss = 14.7582 | Val Loss = 1.3809 | Acc = 0.9261 | AUC = 0.9852 | Precision = 0.8626 | Recall = 0.9479 | F1 = 0.9032 | Best Threshold = 0.6700 | Best F1 = 0.9291\n",
      "Fold 2 - New best F1: 0.9291 at threshold 0.6700 → model saved.\n",
      "[Fold 2] Epoch 2: Train Loss = 9.0838 | Val Loss = 0.9210 | Acc = 0.9337 | AUC = 0.9918 | Precision = 0.8792 | Recall = 0.9479 | F1 = 0.9123 | Best Threshold = 0.7000 | Best F1 = 0.9504\n",
      "Fold 2 - New best F1: 0.9504 at threshold 0.7000 → model saved.\n",
      "[Fold 2] Epoch 3: Train Loss = 6.6178 | Val Loss = 0.7893 | Acc = 0.9489 | AUC = 0.9897 | Precision = 0.9231 | Recall = 0.9375 | F1 = 0.9302 | Best Threshold = 0.6400 | Best F1 = 0.9344\n",
      "[Fold 2] Epoch 4: Train Loss = 5.6125 | Val Loss = 0.7627 | Acc = 0.9413 | AUC = 0.9911 | Precision = 0.8966 | Recall = 0.9479 | F1 = 0.9215 | Best Threshold = 0.7800 | Best F1 = 0.9412\n",
      "[Fold 2] Epoch 5: Train Loss = 4.5718 | Val Loss = 0.7737 | Acc = 0.9470 | AUC = 0.9900 | Precision = 0.9100 | Recall = 0.9479 | F1 = 0.9286 | Best Threshold = 0.4200 | Best F1 = 0.9394\n",
      "[Fold 2] Epoch 6: Train Loss = 3.6668 | Val Loss = 0.6918 | Acc = 0.9527 | AUC = 0.9922 | Precision = 0.9465 | Recall = 0.9219 | F1 = 0.9340 | Best Threshold = 0.5300 | Best F1 = 0.9365\n",
      "[Fold 2] Epoch 7: Train Loss = 2.9623 | Val Loss = 0.7478 | Acc = 0.9489 | AUC = 0.9901 | Precision = 0.9319 | Recall = 0.9271 | F1 = 0.9295 | Best Threshold = 0.6000 | Best F1 = 0.9337\n",
      "[Fold 2] Epoch 8: Train Loss = 1.9221 | Val Loss = 0.6129 | Acc = 0.9545 | AUC = 0.9930 | Precision = 0.9242 | Recall = 0.9531 | F1 = 0.9385 | Best Threshold = 0.6100 | Best F1 = 0.9427\n",
      "[Fold 2] Epoch 9: Train Loss = 2.2584 | Val Loss = 0.7287 | Acc = 0.9508 | AUC = 0.9908 | Precision = 0.9235 | Recall = 0.9427 | F1 = 0.9330 | Best Threshold = 0.3200 | Best F1 = 0.9370\n",
      "[Fold 2] Epoch 10: Train Loss = 2.0691 | Val Loss = 0.7002 | Acc = 0.9640 | AUC = 0.9913 | Precision = 0.9577 | Recall = 0.9427 | F1 = 0.9501 | Best Threshold = 0.4300 | Best F1 = 0.9504\n",
      "[Fold 2] Epoch 11: Train Loss = 1.6233 | Val Loss = 0.8361 | Acc = 0.9451 | AUC = 0.9902 | Precision = 0.9179 | Recall = 0.9323 | F1 = 0.9251 | Best Threshold = 0.5900 | Best F1 = 0.9299\n",
      "Fold 2 - Early stopping at epoch 11\n",
      "\n",
      "📦 Starting Fold 3\n",
      "[Fold 3] Epoch 1: Train Loss = 15.5628 | Val Loss = 1.6573 | Acc = 0.9015 | AUC = 0.9797 | Precision = 0.7966 | Recall = 0.9792 | F1 = 0.8785 | Best Threshold = 0.6500 | Best F1 = 0.9173\n",
      "Fold 3 - New best F1: 0.9173 at threshold 0.6500 → model saved.\n",
      "[Fold 3] Epoch 2: Train Loss = 8.7564 | Val Loss = 1.0884 | Acc = 0.9470 | AUC = 0.9850 | Precision = 0.9059 | Recall = 0.9531 | F1 = 0.9289 | Best Threshold = 0.5400 | Best F1 = 0.9309\n",
      "Fold 3 - New best F1: 0.9309 at threshold 0.5400 → model saved.\n",
      "[Fold 3] Epoch 3: Train Loss = 6.3908 | Val Loss = 1.0435 | Acc = 0.9337 | AUC = 0.9860 | Precision = 0.8720 | Recall = 0.9583 | F1 = 0.9132 | Best Threshold = 0.7800 | Best F1 = 0.9399\n",
      "Fold 3 - New best F1: 0.9399 at threshold 0.7800 → model saved.\n",
      "[Fold 3] Epoch 4: Train Loss = 5.0568 | Val Loss = 1.0027 | Acc = 0.9413 | AUC = 0.9834 | Precision = 0.8889 | Recall = 0.9583 | F1 = 0.9223 | Best Threshold = 0.7600 | Best F1 = 0.9399\n",
      "[Fold 3] Epoch 5: Train Loss = 4.1759 | Val Loss = 1.1495 | Acc = 0.9356 | AUC = 0.9823 | Precision = 0.8762 | Recall = 0.9583 | F1 = 0.9154 | Best Threshold = 0.8400 | Best F1 = 0.9271\n",
      "[Fold 3] Epoch 6: Train Loss = 4.1842 | Val Loss = 1.1529 | Acc = 0.9413 | AUC = 0.9858 | Precision = 0.8852 | Recall = 0.9635 | F1 = 0.9227 | Best Threshold = 0.8200 | Best F1 = 0.9306\n",
      "[Fold 3] Epoch 7: Train Loss = 2.4861 | Val Loss = 1.0529 | Acc = 0.9470 | AUC = 0.9833 | Precision = 0.9059 | Recall = 0.9531 | F1 = 0.9289 | Best Threshold = 0.6100 | Best F1 = 0.9354\n",
      "[Fold 3] Epoch 8: Train Loss = 1.8207 | Val Loss = 1.0815 | Acc = 0.9375 | AUC = 0.9818 | Precision = 0.8916 | Recall = 0.9427 | F1 = 0.9165 | Best Threshold = 0.7600 | Best F1 = 0.9288\n",
      "[Fold 3] Epoch 9: Train Loss = 1.5756 | Val Loss = 1.2044 | Acc = 0.9375 | AUC = 0.9809 | Precision = 0.8916 | Recall = 0.9427 | F1 = 0.9165 | Best Threshold = 0.7600 | Best F1 = 0.9267\n",
      "[Fold 3] Epoch 10: Train Loss = 1.5170 | Val Loss = 1.1969 | Acc = 0.9318 | AUC = 0.9794 | Precision = 0.8750 | Recall = 0.9479 | F1 = 0.9100 | Best Threshold = 0.5900 | Best F1 = 0.9215\n",
      "[Fold 3] Epoch 11: Train Loss = 1.1819 | Val Loss = 1.1221 | Acc = 0.9451 | AUC = 0.9820 | Precision = 0.9015 | Recall = 0.9531 | F1 = 0.9266 | Best Threshold = 0.7700 | Best F1 = 0.9403\n",
      "Fold 3 - New best F1: 0.9403 at threshold 0.7700 → model saved.\n",
      "[Fold 3] Epoch 12: Train Loss = 1.1993 | Val Loss = 1.1530 | Acc = 0.9432 | AUC = 0.9829 | Precision = 0.9010 | Recall = 0.9479 | F1 = 0.9239 | Best Threshold = 0.6500 | Best F1 = 0.9330\n",
      "[Fold 3] Epoch 13: Train Loss = 0.8193 | Val Loss = 1.1694 | Acc = 0.9451 | AUC = 0.9834 | Precision = 0.9015 | Recall = 0.9531 | F1 = 0.9266 | Best Threshold = 0.6700 | Best F1 = 0.9326\n",
      "[Fold 3] Epoch 14: Train Loss = 0.8518 | Val Loss = 1.1639 | Acc = 0.9413 | AUC = 0.9839 | Precision = 0.8966 | Recall = 0.9479 | F1 = 0.9215 | Best Threshold = 0.6300 | Best F1 = 0.9282\n",
      "[Fold 3] Epoch 15: Train Loss = 0.7879 | Val Loss = 1.2155 | Acc = 0.9432 | AUC = 0.9835 | Precision = 0.9010 | Recall = 0.9479 | F1 = 0.9239 | Best Threshold = 0.6000 | Best F1 = 0.9286\n",
      "[Fold 3] Epoch 16: Train Loss = 0.6738 | Val Loss = 1.1739 | Acc = 0.9432 | AUC = 0.9826 | Precision = 0.9091 | Recall = 0.9375 | F1 = 0.9231 | Best Threshold = 0.4600 | Best F1 = 0.9258\n",
      "[Fold 3] Epoch 17: Train Loss = 0.9734 | Val Loss = 1.2544 | Acc = 0.9432 | AUC = 0.9824 | Precision = 0.8971 | Recall = 0.9531 | F1 = 0.9242 | Best Threshold = 0.7600 | Best F1 = 0.9247\n",
      "[Fold 3] Epoch 18: Train Loss = 0.9470 | Val Loss = 1.3087 | Acc = 0.9413 | AUC = 0.9833 | Precision = 0.8966 | Recall = 0.9479 | F1 = 0.9215 | Best Threshold = 0.3600 | Best F1 = 0.9219\n",
      "[Fold 3] Epoch 19: Train Loss = 0.6069 | Val Loss = 1.2943 | Acc = 0.9413 | AUC = 0.9830 | Precision = 0.8927 | Recall = 0.9531 | F1 = 0.9219 | Best Threshold = 0.3600 | Best F1 = 0.9273\n",
      "[Fold 3] Epoch 20: Train Loss = 0.6317 | Val Loss = 1.2508 | Acc = 0.9375 | AUC = 0.9833 | Precision = 0.8995 | Recall = 0.9323 | F1 = 0.9156 | Best Threshold = 0.2600 | Best F1 = 0.9242\n",
      "Fold 3 - Early stopping at epoch 20\n",
      "\n",
      "📦 Starting Fold 4\n",
      "[Fold 4] Epoch 1: Train Loss = 14.2320 | Val Loss = 1.7970 | Acc = 0.8939 | AUC = 0.9732 | Precision = 0.8036 | Recall = 0.9375 | F1 = 0.8654 | Best Threshold = 0.6200 | Best F1 = 0.8834\n",
      "Fold 4 - New best F1: 0.8834 at threshold 0.6200 → model saved.\n",
      "[Fold 4] Epoch 2: Train Loss = 8.1863 | Val Loss = 1.5641 | Acc = 0.9110 | AUC = 0.9754 | Precision = 0.8404 | Recall = 0.9323 | F1 = 0.8840 | Best Threshold = 0.7300 | Best F1 = 0.8930\n",
      "Fold 4 - New best F1: 0.8930 at threshold 0.7300 → model saved.\n",
      "[Fold 4] Epoch 3: Train Loss = 5.9670 | Val Loss = 1.4851 | Acc = 0.9280 | AUC = 0.9782 | Precision = 0.8775 | Recall = 0.9323 | F1 = 0.9040 | Best Threshold = 0.6600 | Best F1 = 0.9152\n",
      "Fold 4 - New best F1: 0.9152 at threshold 0.6600 → model saved.\n",
      "[Fold 4] Epoch 4: Train Loss = 4.5273 | Val Loss = 1.7283 | Acc = 0.9129 | AUC = 0.9769 | Precision = 0.8443 | Recall = 0.9323 | F1 = 0.8861 | Best Threshold = 0.6500 | Best F1 = 0.9031\n",
      "[Fold 4] Epoch 5: Train Loss = 3.9634 | Val Loss = 1.7017 | Acc = 0.9205 | AUC = 0.9750 | Precision = 0.8571 | Recall = 0.9375 | F1 = 0.8955 | Best Threshold = 0.6700 | Best F1 = 0.9072\n",
      "[Fold 4] Epoch 6: Train Loss = 3.8030 | Val Loss = 1.8341 | Acc = 0.9148 | AUC = 0.9774 | Precision = 0.8451 | Recall = 0.9375 | F1 = 0.8889 | Best Threshold = 0.8200 | Best F1 = 0.9021\n",
      "[Fold 4] Epoch 7: Train Loss = 3.1482 | Val Loss = 1.5080 | Acc = 0.9205 | AUC = 0.9793 | Precision = 0.8571 | Recall = 0.9375 | F1 = 0.8955 | Best Threshold = 0.4700 | Best F1 = 0.8983\n",
      "[Fold 4] Epoch 8: Train Loss = 1.8975 | Val Loss = 1.4965 | Acc = 0.9318 | AUC = 0.9788 | Precision = 0.8786 | Recall = 0.9427 | F1 = 0.9095 | Best Threshold = 0.6800 | Best F1 = 0.9137\n",
      "[Fold 4] Epoch 9: Train Loss = 1.3896 | Val Loss = 1.6331 | Acc = 0.9280 | AUC = 0.9792 | Precision = 0.8702 | Recall = 0.9427 | F1 = 0.9050 | Best Threshold = 0.6400 | Best F1 = 0.9114\n",
      "[Fold 4] Epoch 10: Train Loss = 1.3074 | Val Loss = 1.7934 | Acc = 0.9261 | AUC = 0.9779 | Precision = 0.8696 | Recall = 0.9375 | F1 = 0.9023 | Best Threshold = 0.8200 | Best F1 = 0.9124\n",
      "[Fold 4] Epoch 11: Train Loss = 1.5341 | Val Loss = 2.0860 | Acc = 0.9223 | AUC = 0.9788 | Precision = 0.8545 | Recall = 0.9479 | F1 = 0.8988 | Best Threshold = 0.8500 | Best F1 = 0.9026\n",
      "[Fold 4] Epoch 12: Train Loss = 1.5486 | Val Loss = 1.9526 | Acc = 0.9242 | AUC = 0.9742 | Precision = 0.8689 | Recall = 0.9323 | F1 = 0.8995 | Best Threshold = 0.5600 | Best F1 = 0.9040\n",
      "Fold 4 - Early stopping at epoch 12\n",
      "\n",
      "📦 Starting Fold 5\n",
      "[Fold 5] Epoch 1: Train Loss = 14.9480 | Val Loss = 1.3281 | Acc = 0.9413 | AUC = 0.9872 | Precision = 0.8927 | Recall = 0.9531 | F1 = 0.9219 | Best Threshold = 0.5700 | Best F1 = 0.9282\n",
      "Fold 5 - New best F1: 0.9282 at threshold 0.5700 → model saved.\n",
      "[Fold 5] Epoch 2: Train Loss = 8.7643 | Val Loss = 0.9796 | Acc = 0.9432 | AUC = 0.9898 | Precision = 0.9010 | Recall = 0.9479 | F1 = 0.9239 | Best Threshold = 0.7100 | Best F1 = 0.9319\n",
      "Fold 5 - New best F1: 0.9319 at threshold 0.7100 → model saved.\n",
      "[Fold 5] Epoch 3: Train Loss = 6.2602 | Val Loss = 0.8168 | Acc = 0.9545 | AUC = 0.9877 | Precision = 0.9375 | Recall = 0.9375 | F1 = 0.9375 | Best Threshold = 0.4800 | Best F1 = 0.9375\n",
      "Fold 5 - New best F1: 0.9375 at threshold 0.4800 → model saved.\n",
      "[Fold 5] Epoch 4: Train Loss = 4.8169 | Val Loss = 0.7698 | Acc = 0.9489 | AUC = 0.9877 | Precision = 0.9275 | Recall = 0.9323 | F1 = 0.9299 | Best Threshold = 0.3500 | Best F1 = 0.9367\n",
      "[Fold 5] Epoch 5: Train Loss = 3.9108 | Val Loss = 0.8840 | Acc = 0.9470 | AUC = 0.9847 | Precision = 0.9184 | Recall = 0.9375 | F1 = 0.9278 | Best Threshold = 0.7100 | Best F1 = 0.9340\n",
      "[Fold 5] Epoch 6: Train Loss = 3.8402 | Val Loss = 0.9122 | Acc = 0.9489 | AUC = 0.9902 | Precision = 0.9365 | Recall = 0.9219 | F1 = 0.9291 | Best Threshold = 0.3000 | Best F1 = 0.9433\n",
      "Fold 5 - New best F1: 0.9433 at threshold 0.3000 → model saved.\n",
      "[Fold 5] Epoch 7: Train Loss = 3.4968 | Val Loss = 0.8232 | Acc = 0.9508 | AUC = 0.9884 | Precision = 0.9368 | Recall = 0.9271 | F1 = 0.9319 | Best Threshold = 0.2500 | Best F1 = 0.9439\n",
      "Fold 5 - New best F1: 0.9439 at threshold 0.2500 → model saved.\n",
      "[Fold 5] Epoch 8: Train Loss = 2.1972 | Val Loss = 0.9070 | Acc = 0.9508 | AUC = 0.9877 | Precision = 0.9415 | Recall = 0.9219 | F1 = 0.9316 | Best Threshold = 0.4100 | Best F1 = 0.9347\n",
      "[Fold 5] Epoch 9: Train Loss = 1.8577 | Val Loss = 0.8058 | Acc = 0.9527 | AUC = 0.9883 | Precision = 0.9326 | Recall = 0.9375 | F1 = 0.9351 | Best Threshold = 0.4900 | Best F1 = 0.9351\n",
      "[Fold 5] Epoch 10: Train Loss = 1.2238 | Val Loss = 0.8756 | Acc = 0.9470 | AUC = 0.9889 | Precision = 0.9271 | Recall = 0.9271 | F1 = 0.9271 | Best Threshold = 0.1600 | Best F1 = 0.9466\n",
      "Fold 5 - New best F1: 0.9466 at threshold 0.1600 → model saved.\n",
      "[Fold 5] Epoch 11: Train Loss = 1.0868 | Val Loss = 0.9474 | Acc = 0.9432 | AUC = 0.9869 | Precision = 0.9219 | Recall = 0.9219 | F1 = 0.9219 | Best Threshold = 0.2700 | Best F1 = 0.9313\n",
      "[Fold 5] Epoch 12: Train Loss = 0.9141 | Val Loss = 1.1887 | Acc = 0.9413 | AUC = 0.9868 | Precision = 0.9259 | Recall = 0.9115 | F1 = 0.9186 | Best Threshold = 0.1000 | Best F1 = 0.9340\n",
      "[Fold 5] Epoch 13: Train Loss = 0.9485 | Val Loss = 0.8551 | Acc = 0.9470 | AUC = 0.9878 | Precision = 0.9227 | Recall = 0.9323 | F1 = 0.9275 | Best Threshold = 0.1900 | Best F1 = 0.9370\n",
      "[Fold 5] Epoch 14: Train Loss = 0.8926 | Val Loss = 0.8889 | Acc = 0.9489 | AUC = 0.9862 | Precision = 0.9275 | Recall = 0.9323 | F1 = 0.9299 | Best Threshold = 0.2700 | Best F1 = 0.9415\n",
      "[Fold 5] Epoch 15: Train Loss = 0.7220 | Val Loss = 1.0453 | Acc = 0.9413 | AUC = 0.9860 | Precision = 0.9259 | Recall = 0.9115 | F1 = 0.9186 | Best Threshold = 0.1200 | Best F1 = 0.9394\n",
      "[Fold 5] Epoch 16: Train Loss = 0.6477 | Val Loss = 1.0029 | Acc = 0.9451 | AUC = 0.9861 | Precision = 0.9312 | Recall = 0.9167 | F1 = 0.9239 | Best Threshold = 0.2300 | Best F1 = 0.9439\n",
      "[Fold 5] Epoch 17: Train Loss = 0.4777 | Val Loss = 0.9298 | Acc = 0.9489 | AUC = 0.9861 | Precision = 0.9188 | Recall = 0.9427 | F1 = 0.9306 | Best Threshold = 0.2300 | Best F1 = 0.9418\n",
      "[Fold 5] Epoch 18: Train Loss = 0.6095 | Val Loss = 0.9874 | Acc = 0.9432 | AUC = 0.9862 | Precision = 0.9175 | Recall = 0.9271 | F1 = 0.9223 | Best Threshold = 0.1600 | Best F1 = 0.9394\n",
      "[Fold 5] Epoch 19: Train Loss = 0.8199 | Val Loss = 0.9983 | Acc = 0.9470 | AUC = 0.9863 | Precision = 0.9227 | Recall = 0.9323 | F1 = 0.9275 | Best Threshold = 0.1100 | Best F1 = 0.9397\n",
      "Fold 5 - Early stopping at epoch 19\n",
      "\n",
      "📦 Starting Fold 6\n",
      "[Fold 6] Epoch 1: Train Loss = 14.8364 | Val Loss = 1.5212 | Acc = 0.9205 | AUC = 0.9794 | Precision = 0.8319 | Recall = 0.9792 | F1 = 0.8995 | Best Threshold = 0.5600 | Best F1 = 0.9126\n",
      "Fold 6 - New best F1: 0.9126 at threshold 0.5600 → model saved.\n",
      "[Fold 6] Epoch 2: Train Loss = 9.1350 | Val Loss = 1.1534 | Acc = 0.9356 | AUC = 0.9814 | Precision = 0.8798 | Recall = 0.9531 | F1 = 0.9150 | Best Threshold = 0.5400 | Best F1 = 0.9215\n",
      "Fold 6 - New best F1: 0.9215 at threshold 0.5400 → model saved.\n",
      "[Fold 6] Epoch 3: Train Loss = 6.6505 | Val Loss = 1.1304 | Acc = 0.9337 | AUC = 0.9836 | Precision = 0.8720 | Recall = 0.9583 | F1 = 0.9132 | Best Threshold = 0.6000 | Best F1 = 0.9223\n",
      "Fold 6 - New best F1: 0.9223 at threshold 0.6000 → model saved.\n",
      "[Fold 6] Epoch 4: Train Loss = 4.9418 | Val Loss = 1.4421 | Acc = 0.9375 | AUC = 0.9821 | Precision = 0.9036 | Recall = 0.9271 | F1 = 0.9152 | Best Threshold = 0.3600 | Best F1 = 0.9277\n",
      "Fold 6 - New best F1: 0.9277 at threshold 0.3600 → model saved.\n",
      "[Fold 6] Epoch 5: Train Loss = 3.6399 | Val Loss = 1.2795 | Acc = 0.9337 | AUC = 0.9829 | Precision = 0.8905 | Recall = 0.9323 | F1 = 0.9109 | Best Threshold = 0.2500 | Best F1 = 0.9185\n",
      "[Fold 6] Epoch 6: Train Loss = 2.8032 | Val Loss = 1.5221 | Acc = 0.9318 | AUC = 0.9791 | Precision = 0.8900 | Recall = 0.9271 | F1 = 0.9082 | Best Threshold = 0.8300 | Best F1 = 0.9223\n",
      "[Fold 6] Epoch 7: Train Loss = 2.4267 | Val Loss = 1.2466 | Acc = 0.9356 | AUC = 0.9821 | Precision = 0.8990 | Recall = 0.9271 | F1 = 0.9128 | Best Threshold = 0.7900 | Best F1 = 0.9202\n",
      "[Fold 6] Epoch 8: Train Loss = 2.3874 | Val Loss = 1.5563 | Acc = 0.9318 | AUC = 0.9803 | Precision = 0.8861 | Recall = 0.9323 | F1 = 0.9086 | Best Threshold = 0.6800 | Best F1 = 0.9171\n",
      "[Fold 6] Epoch 9: Train Loss = 1.9644 | Val Loss = 1.4103 | Acc = 0.9356 | AUC = 0.9836 | Precision = 0.8873 | Recall = 0.9427 | F1 = 0.9141 | Best Threshold = 0.7900 | Best F1 = 0.9227\n",
      "[Fold 6] Epoch 10: Train Loss = 1.9143 | Val Loss = 1.5428 | Acc = 0.9432 | AUC = 0.9850 | Precision = 0.9175 | Recall = 0.9271 | F1 = 0.9223 | Best Threshold = 0.1900 | Best F1 = 0.9277\n",
      "[Fold 6] Epoch 11: Train Loss = 1.0257 | Val Loss = 1.4280 | Acc = 0.9375 | AUC = 0.9843 | Precision = 0.9119 | Recall = 0.9167 | F1 = 0.9143 | Best Threshold = 0.3400 | Best F1 = 0.9289\n",
      "Fold 6 - New best F1: 0.9289 at threshold 0.3400 → model saved.\n",
      "[Fold 6] Epoch 12: Train Loss = 1.1210 | Val Loss = 1.5184 | Acc = 0.9432 | AUC = 0.9830 | Precision = 0.9091 | Recall = 0.9375 | F1 = 0.9231 | Best Threshold = 0.7000 | Best F1 = 0.9251\n",
      "[Fold 6] Epoch 13: Train Loss = 0.9559 | Val Loss = 1.5598 | Acc = 0.9356 | AUC = 0.9829 | Precision = 0.9031 | Recall = 0.9219 | F1 = 0.9124 | Best Threshold = 0.5800 | Best F1 = 0.9195\n",
      "[Fold 6] Epoch 14: Train Loss = 0.9045 | Val Loss = 1.4998 | Acc = 0.9337 | AUC = 0.9825 | Precision = 0.9026 | Recall = 0.9167 | F1 = 0.9096 | Best Threshold = 0.7300 | Best F1 = 0.9284\n",
      "[Fold 6] Epoch 15: Train Loss = 1.2095 | Val Loss = 1.4404 | Acc = 0.9451 | AUC = 0.9841 | Precision = 0.9095 | Recall = 0.9427 | F1 = 0.9258 | Best Threshold = 0.4700 | Best F1 = 0.9258\n",
      "[Fold 6] Epoch 16: Train Loss = 0.8726 | Val Loss = 1.6945 | Acc = 0.9451 | AUC = 0.9822 | Precision = 0.9179 | Recall = 0.9323 | F1 = 0.9251 | Best Threshold = 0.5400 | Best F1 = 0.9275\n",
      "[Fold 6] Epoch 17: Train Loss = 0.6310 | Val Loss = 1.3817 | Acc = 0.9413 | AUC = 0.9846 | Precision = 0.9045 | Recall = 0.9375 | F1 = 0.9207 | Best Threshold = 0.7500 | Best F1 = 0.9291\n",
      "Fold 6 - New best F1: 0.9291 at threshold 0.7500 → model saved.\n",
      "[Fold 6] Epoch 18: Train Loss = 0.7872 | Val Loss = 1.5614 | Acc = 0.9413 | AUC = 0.9827 | Precision = 0.9005 | Recall = 0.9427 | F1 = 0.9211 | Best Threshold = 0.4400 | Best F1 = 0.9242\n",
      "[Fold 6] Epoch 19: Train Loss = 0.6323 | Val Loss = 1.7604 | Acc = 0.9432 | AUC = 0.9837 | Precision = 0.9091 | Recall = 0.9375 | F1 = 0.9231 | Best Threshold = 0.6600 | Best F1 = 0.9275\n",
      "[Fold 6] Epoch 20: Train Loss = 1.8966 | Val Loss = 1.5746 | Acc = 0.9413 | AUC = 0.9851 | Precision = 0.9045 | Recall = 0.9375 | F1 = 0.9207 | Best Threshold = 0.6600 | Best F1 = 0.9275\n",
      "[Fold 6] Epoch 21: Train Loss = 0.7565 | Val Loss = 1.4246 | Acc = 0.9451 | AUC = 0.9851 | Precision = 0.9095 | Recall = 0.9427 | F1 = 0.9258 | Best Threshold = 0.7700 | Best F1 = 0.9351\n",
      "Fold 6 - New best F1: 0.9351 at threshold 0.7700 → model saved.\n",
      "[Fold 6] Epoch 22: Train Loss = 0.5180 | Val Loss = 1.4595 | Acc = 0.9356 | AUC = 0.9844 | Precision = 0.8873 | Recall = 0.9427 | F1 = 0.9141 | Best Threshold = 0.7300 | Best F1 = 0.9299\n",
      "[Fold 6] Epoch 23: Train Loss = 0.3394 | Val Loss = 1.5826 | Acc = 0.9375 | AUC = 0.9843 | Precision = 0.8955 | Recall = 0.9375 | F1 = 0.9160 | Best Threshold = 0.7800 | Best F1 = 0.9316\n",
      "[Fold 6] Epoch 24: Train Loss = 0.3217 | Val Loss = 1.6499 | Acc = 0.9394 | AUC = 0.9842 | Precision = 0.9000 | Recall = 0.9375 | F1 = 0.9184 | Best Threshold = 0.8700 | Best F1 = 0.9284\n",
      "[Fold 6] Epoch 25: Train Loss = 1.1037 | Val Loss = 1.8188 | Acc = 0.9432 | AUC = 0.9845 | Precision = 0.9175 | Recall = 0.9271 | F1 = 0.9223 | Best Threshold = 0.8200 | Best F1 = 0.9251\n",
      "[Fold 6] Epoch 26: Train Loss = 1.0165 | Val Loss = 1.8408 | Acc = 0.9451 | AUC = 0.9820 | Precision = 0.9267 | Recall = 0.9219 | F1 = 0.9243 | Best Threshold = 0.6300 | Best F1 = 0.9263\n",
      "[Fold 6] Epoch 27: Train Loss = 0.4128 | Val Loss = 1.7794 | Acc = 0.9337 | AUC = 0.9813 | Precision = 0.8867 | Recall = 0.9375 | F1 = 0.9114 | Best Threshold = 0.8800 | Best F1 = 0.9263\n",
      "[Fold 6] Epoch 28: Train Loss = 0.6341 | Val Loss = 1.7441 | Acc = 0.9356 | AUC = 0.9819 | Precision = 0.8835 | Recall = 0.9479 | F1 = 0.9146 | Best Threshold = 0.8600 | Best F1 = 0.9243\n",
      "[Fold 6] Epoch 29: Train Loss = 0.3293 | Val Loss = 1.8723 | Acc = 0.9318 | AUC = 0.9812 | Precision = 0.8900 | Recall = 0.9271 | F1 = 0.9082 | Best Threshold = 0.6300 | Best F1 = 0.9247\n",
      "[Fold 6] Epoch 30: Train Loss = 0.3935 | Val Loss = 1.7990 | Acc = 0.9280 | AUC = 0.9819 | Precision = 0.8812 | Recall = 0.9271 | F1 = 0.9036 | Best Threshold = 0.8900 | Best F1 = 0.9231\n",
      "Fold 6 - Early stopping at epoch 30\n",
      "\n",
      "📦 Starting Fold 7\n",
      "[Fold 7] Epoch 1: Train Loss = 15.0378 | Val Loss = 1.5728 | Acc = 0.9110 | AUC = 0.9746 | Precision = 0.8372 | Recall = 0.9375 | F1 = 0.8845 | Best Threshold = 0.6700 | Best F1 = 0.8889\n",
      "Fold 7 - New best F1: 0.8889 at threshold 0.6700 → model saved.\n",
      "[Fold 7] Epoch 2: Train Loss = 9.0380 | Val Loss = 1.1845 | Acc = 0.9261 | AUC = 0.9828 | Precision = 0.8768 | Recall = 0.9271 | F1 = 0.9013 | Best Threshold = 0.7300 | Best F1 = 0.9077\n",
      "Fold 7 - New best F1: 0.9077 at threshold 0.7300 → model saved.\n",
      "[Fold 7] Epoch 3: Train Loss = 7.0165 | Val Loss = 1.1719 | Acc = 0.9356 | AUC = 0.9804 | Precision = 0.8835 | Recall = 0.9479 | F1 = 0.9146 | Best Threshold = 0.6500 | Best F1 = 0.9179\n",
      "Fold 7 - New best F1: 0.9179 at threshold 0.6500 → model saved.\n",
      "[Fold 7] Epoch 4: Train Loss = 5.5112 | Val Loss = 1.0405 | Acc = 0.9413 | AUC = 0.9855 | Precision = 0.9128 | Recall = 0.9271 | F1 = 0.9199 | Best Threshold = 0.5500 | Best F1 = 0.9243\n",
      "Fold 7 - New best F1: 0.9243 at threshold 0.5500 → model saved.\n",
      "[Fold 7] Epoch 5: Train Loss = 4.2744 | Val Loss = 1.0965 | Acc = 0.9375 | AUC = 0.9854 | Precision = 0.8955 | Recall = 0.9375 | F1 = 0.9160 | Best Threshold = 0.4600 | Best F1 = 0.9215\n",
      "[Fold 7] Epoch 6: Train Loss = 3.8570 | Val Loss = 1.1155 | Acc = 0.9337 | AUC = 0.9851 | Precision = 0.9067 | Recall = 0.9115 | F1 = 0.9091 | Best Threshold = 0.2600 | Best F1 = 0.9141\n",
      "[Fold 7] Epoch 7: Train Loss = 3.1462 | Val Loss = 1.0480 | Acc = 0.9432 | AUC = 0.9861 | Precision = 0.9219 | Recall = 0.9219 | F1 = 0.9219 | Best Threshold = 0.5600 | Best F1 = 0.9259\n",
      "Fold 7 - New best F1: 0.9259 at threshold 0.5600 → model saved.\n",
      "[Fold 7] Epoch 8: Train Loss = 2.7708 | Val Loss = 1.2977 | Acc = 0.9318 | AUC = 0.9840 | Precision = 0.8900 | Recall = 0.9271 | F1 = 0.9082 | Best Threshold = 0.4000 | Best F1 = 0.9146\n",
      "[Fold 7] Epoch 9: Train Loss = 2.5904 | Val Loss = 1.4611 | Acc = 0.9318 | AUC = 0.9777 | Precision = 0.9149 | Recall = 0.8958 | F1 = 0.9053 | Best Threshold = 0.3600 | Best F1 = 0.9128\n",
      "[Fold 7] Epoch 10: Train Loss = 1.9620 | Val Loss = 1.2772 | Acc = 0.9375 | AUC = 0.9844 | Precision = 0.9036 | Recall = 0.9271 | F1 = 0.9152 | Best Threshold = 0.5400 | Best F1 = 0.9195\n",
      "[Fold 7] Epoch 11: Train Loss = 1.7884 | Val Loss = 1.3624 | Acc = 0.9375 | AUC = 0.9853 | Precision = 0.8955 | Recall = 0.9375 | F1 = 0.9160 | Best Threshold = 0.4500 | Best F1 = 0.9188\n",
      "[Fold 7] Epoch 12: Train Loss = 1.1577 | Val Loss = 1.3123 | Acc = 0.9394 | AUC = 0.9839 | Precision = 0.9040 | Recall = 0.9323 | F1 = 0.9179 | Best Threshold = 0.7300 | Best F1 = 0.9263\n",
      "Fold 7 - New best F1: 0.9263 at threshold 0.7300 → model saved.\n",
      "[Fold 7] Epoch 13: Train Loss = 1.2082 | Val Loss = 1.3610 | Acc = 0.9394 | AUC = 0.9834 | Precision = 0.9082 | Recall = 0.9271 | F1 = 0.9175 | Best Threshold = 0.2700 | Best F1 = 0.9289\n",
      "Fold 7 - New best F1: 0.9289 at threshold 0.2700 → model saved.\n",
      "[Fold 7] Epoch 14: Train Loss = 0.8216 | Val Loss = 1.4642 | Acc = 0.9394 | AUC = 0.9839 | Precision = 0.8960 | Recall = 0.9427 | F1 = 0.9188 | Best Threshold = 0.6000 | Best F1 = 0.9235\n",
      "[Fold 7] Epoch 15: Train Loss = 0.6305 | Val Loss = 1.4407 | Acc = 0.9375 | AUC = 0.9834 | Precision = 0.8878 | Recall = 0.9479 | F1 = 0.9169 | Best Threshold = 0.7900 | Best F1 = 0.9299\n",
      "Fold 7 - New best F1: 0.9299 at threshold 0.7900 → model saved.\n",
      "[Fold 7] Epoch 16: Train Loss = 1.4398 | Val Loss = 1.3667 | Acc = 0.9489 | AUC = 0.9833 | Precision = 0.9319 | Recall = 0.9271 | F1 = 0.9295 | Best Threshold = 0.4800 | Best F1 = 0.9323\n",
      "Fold 7 - New best F1: 0.9323 at threshold 0.4800 → model saved.\n",
      "[Fold 7] Epoch 17: Train Loss = 0.8364 | Val Loss = 1.4920 | Acc = 0.9337 | AUC = 0.9830 | Precision = 0.8756 | Recall = 0.9531 | F1 = 0.9127 | Best Threshold = 0.6400 | Best F1 = 0.9239\n",
      "[Fold 7] Epoch 18: Train Loss = 0.6019 | Val Loss = 1.3296 | Acc = 0.9413 | AUC = 0.9837 | Precision = 0.9005 | Recall = 0.9427 | F1 = 0.9211 | Best Threshold = 0.6300 | Best F1 = 0.9275\n",
      "[Fold 7] Epoch 19: Train Loss = 0.4199 | Val Loss = 1.3914 | Acc = 0.9470 | AUC = 0.9845 | Precision = 0.9100 | Recall = 0.9479 | F1 = 0.9286 | Best Threshold = 0.5000 | Best F1 = 0.9286\n",
      "[Fold 7] Epoch 20: Train Loss = 0.5093 | Val Loss = 1.4054 | Acc = 0.9451 | AUC = 0.9843 | Precision = 0.9095 | Recall = 0.9427 | F1 = 0.9258 | Best Threshold = 0.6000 | Best F1 = 0.9282\n",
      "[Fold 7] Epoch 21: Train Loss = 0.5044 | Val Loss = 1.3887 | Acc = 0.9451 | AUC = 0.9841 | Precision = 0.9095 | Recall = 0.9427 | F1 = 0.9258 | Best Threshold = 0.5700 | Best F1 = 0.9278\n",
      "[Fold 7] Epoch 22: Train Loss = 0.4294 | Val Loss = 1.4300 | Acc = 0.9432 | AUC = 0.9839 | Precision = 0.9050 | Recall = 0.9427 | F1 = 0.9235 | Best Threshold = 0.8500 | Best F1 = 0.9284\n",
      "[Fold 7] Epoch 23: Train Loss = 0.4811 | Val Loss = 1.4489 | Acc = 0.9337 | AUC = 0.9834 | Precision = 0.9067 | Recall = 0.9115 | F1 = 0.9091 | Best Threshold = 0.1500 | Best F1 = 0.9266\n",
      "[Fold 7] Epoch 24: Train Loss = 0.4188 | Val Loss = 1.4533 | Acc = 0.9413 | AUC = 0.9840 | Precision = 0.9086 | Recall = 0.9323 | F1 = 0.9203 | Best Threshold = 0.3000 | Best F1 = 0.9286\n",
      "[Fold 7] Epoch 25: Train Loss = 0.3923 | Val Loss = 1.4920 | Acc = 0.9413 | AUC = 0.9843 | Precision = 0.9005 | Recall = 0.9427 | F1 = 0.9211 | Best Threshold = 0.6000 | Best F1 = 0.9282\n",
      "Fold 7 - Early stopping at epoch 25\n",
      "\n",
      "📦 Starting Fold 8\n",
      "[Fold 8] Epoch 1: Train Loss = 15.2612 | Val Loss = 1.4213 | Acc = 0.9318 | AUC = 0.9808 | Precision = 0.8750 | Recall = 0.9479 | F1 = 0.9100 | Best Threshold = 0.5100 | Best F1 = 0.9123\n",
      "Fold 8 - New best F1: 0.9123 at threshold 0.5100 → model saved.\n",
      "[Fold 8] Epoch 2: Train Loss = 8.6426 | Val Loss = 1.0549 | Acc = 0.9375 | AUC = 0.9854 | Precision = 0.8804 | Recall = 0.9583 | F1 = 0.9177 | Best Threshold = 0.5800 | Best F1 = 0.9293\n",
      "Fold 8 - New best F1: 0.9293 at threshold 0.5800 → model saved.\n",
      "[Fold 8] Epoch 3: Train Loss = 6.6553 | Val Loss = 0.9859 | Acc = 0.9356 | AUC = 0.9848 | Precision = 0.8873 | Recall = 0.9427 | F1 = 0.9141 | Best Threshold = 0.6400 | Best F1 = 0.9199\n",
      "[Fold 8] Epoch 4: Train Loss = 5.9647 | Val Loss = 1.0463 | Acc = 0.9337 | AUC = 0.9813 | Precision = 0.8867 | Recall = 0.9375 | F1 = 0.9114 | Best Threshold = 0.7900 | Best F1 = 0.9302\n",
      "Fold 8 - New best F1: 0.9302 at threshold 0.7900 → model saved.\n",
      "[Fold 8] Epoch 5: Train Loss = 4.3846 | Val Loss = 0.9828 | Acc = 0.9394 | AUC = 0.9801 | Precision = 0.9040 | Recall = 0.9323 | F1 = 0.9179 | Best Threshold = 0.5100 | Best F1 = 0.9227\n",
      "[Fold 8] Epoch 6: Train Loss = 3.3208 | Val Loss = 0.9801 | Acc = 0.9451 | AUC = 0.9813 | Precision = 0.9015 | Recall = 0.9531 | F1 = 0.9266 | Best Threshold = 0.6300 | Best F1 = 0.9299\n",
      "[Fold 8] Epoch 7: Train Loss = 2.3000 | Val Loss = 1.0519 | Acc = 0.9375 | AUC = 0.9796 | Precision = 0.8916 | Recall = 0.9427 | F1 = 0.9165 | Best Threshold = 0.1400 | Best F1 = 0.9167\n",
      "[Fold 8] Epoch 8: Train Loss = 2.2456 | Val Loss = 1.2442 | Acc = 0.9394 | AUC = 0.9796 | Precision = 0.9040 | Recall = 0.9323 | F1 = 0.9179 | Best Threshold = 0.3900 | Best F1 = 0.9215\n",
      "[Fold 8] Epoch 9: Train Loss = 2.9314 | Val Loss = 1.0493 | Acc = 0.9375 | AUC = 0.9823 | Precision = 0.8916 | Recall = 0.9427 | F1 = 0.9165 | Best Threshold = 0.5500 | Best F1 = 0.9188\n",
      "[Fold 8] Epoch 10: Train Loss = 2.1849 | Val Loss = 0.9634 | Acc = 0.9432 | AUC = 0.9814 | Precision = 0.9050 | Recall = 0.9427 | F1 = 0.9235 | Best Threshold = 0.7700 | Best F1 = 0.9291\n",
      "[Fold 8] Epoch 11: Train Loss = 1.2443 | Val Loss = 0.9392 | Acc = 0.9451 | AUC = 0.9834 | Precision = 0.9095 | Recall = 0.9427 | F1 = 0.9258 | Best Threshold = 0.5100 | Best F1 = 0.9282\n",
      "[Fold 8] Epoch 12: Train Loss = 1.3998 | Val Loss = 1.1209 | Acc = 0.9413 | AUC = 0.9803 | Precision = 0.9045 | Recall = 0.9375 | F1 = 0.9207 | Best Threshold = 0.6800 | Best F1 = 0.9275\n",
      "[Fold 8] Epoch 13: Train Loss = 1.3251 | Val Loss = 1.0756 | Acc = 0.9413 | AUC = 0.9801 | Precision = 0.9005 | Recall = 0.9427 | F1 = 0.9211 | Best Threshold = 0.3500 | Best F1 = 0.9219\n",
      "Fold 8 - Early stopping at epoch 13\n",
      "\n",
      "📦 Starting Fold 9\n",
      "[Fold 9] Epoch 1: Train Loss = 15.3283 | Val Loss = 1.3836 | Acc = 0.9261 | AUC = 0.9825 | Precision = 0.8660 | Recall = 0.9427 | F1 = 0.9027 | Best Threshold = 0.4500 | Best F1 = 0.9086\n",
      "Fold 9 - New best F1: 0.9086 at threshold 0.4500 → model saved.\n",
      "[Fold 9] Epoch 2: Train Loss = 8.8368 | Val Loss = 1.0019 | Acc = 0.9470 | AUC = 0.9866 | Precision = 0.9227 | Recall = 0.9323 | F1 = 0.9275 | Best Threshold = 0.6700 | Best F1 = 0.9340\n",
      "Fold 9 - New best F1: 0.9340 at threshold 0.6700 → model saved.\n",
      "[Fold 9] Epoch 3: Train Loss = 6.5338 | Val Loss = 0.9252 | Acc = 0.9470 | AUC = 0.9878 | Precision = 0.9409 | Recall = 0.9115 | F1 = 0.9259 | Best Threshold = 0.3200 | Best F1 = 0.9286\n",
      "[Fold 9] Epoch 4: Train Loss = 5.2184 | Val Loss = 0.8770 | Acc = 0.9470 | AUC = 0.9881 | Precision = 0.9316 | Recall = 0.9219 | F1 = 0.9267 | Best Threshold = 0.4000 | Best F1 = 0.9330\n",
      "[Fold 9] Epoch 5: Train Loss = 4.2665 | Val Loss = 0.9715 | Acc = 0.9489 | AUC = 0.9845 | Precision = 0.9459 | Recall = 0.9115 | F1 = 0.9284 | Best Threshold = 0.4500 | Best F1 = 0.9316\n",
      "[Fold 9] Epoch 6: Train Loss = 4.0261 | Val Loss = 0.9101 | Acc = 0.9432 | AUC = 0.9865 | Precision = 0.9263 | Recall = 0.9167 | F1 = 0.9215 | Best Threshold = 0.2300 | Best F1 = 0.9273\n",
      "[Fold 9] Epoch 7: Train Loss = 3.8655 | Val Loss = 1.0205 | Acc = 0.9451 | AUC = 0.9859 | Precision = 0.9137 | Recall = 0.9375 | F1 = 0.9254 | Best Threshold = 0.7700 | Best F1 = 0.9305\n",
      "[Fold 9] Epoch 8: Train Loss = 3.1403 | Val Loss = 0.9733 | Acc = 0.9299 | AUC = 0.9866 | Precision = 0.8780 | Recall = 0.9375 | F1 = 0.9068 | Best Threshold = 0.7500 | Best F1 = 0.9421\n",
      "Fold 9 - New best F1: 0.9421 at threshold 0.7500 → model saved.\n",
      "[Fold 9] Epoch 9: Train Loss = 2.1457 | Val Loss = 0.9213 | Acc = 0.9394 | AUC = 0.9873 | Precision = 0.9255 | Recall = 0.9062 | F1 = 0.9158 | Best Threshold = 0.4200 | Best F1 = 0.9278\n",
      "[Fold 9] Epoch 10: Train Loss = 2.0946 | Val Loss = 1.0038 | Acc = 0.9451 | AUC = 0.9868 | Precision = 0.9358 | Recall = 0.9115 | F1 = 0.9235 | Best Threshold = 0.5300 | Best F1 = 0.9284\n",
      "[Fold 9] Epoch 11: Train Loss = 1.6703 | Val Loss = 1.0041 | Acc = 0.9508 | AUC = 0.9843 | Precision = 0.9368 | Recall = 0.9271 | F1 = 0.9319 | Best Threshold = 0.4500 | Best F1 = 0.9319\n",
      "[Fold 9] Epoch 12: Train Loss = 1.7962 | Val Loss = 0.9757 | Acc = 0.9413 | AUC = 0.9863 | Precision = 0.9171 | Recall = 0.9219 | F1 = 0.9195 | Best Threshold = 0.7100 | Best F1 = 0.9316\n",
      "[Fold 9] Epoch 13: Train Loss = 1.4771 | Val Loss = 1.0173 | Acc = 0.9432 | AUC = 0.9844 | Precision = 0.9175 | Recall = 0.9271 | F1 = 0.9223 | Best Threshold = 0.1500 | Best F1 = 0.9273\n",
      "[Fold 9] Epoch 14: Train Loss = 0.8993 | Val Loss = 1.0813 | Acc = 0.9432 | AUC = 0.9851 | Precision = 0.9309 | Recall = 0.9115 | F1 = 0.9211 | Best Threshold = 0.6500 | Best F1 = 0.9333\n",
      "[Fold 9] Epoch 15: Train Loss = 0.9343 | Val Loss = 1.0631 | Acc = 0.9545 | AUC = 0.9846 | Precision = 0.9516 | Recall = 0.9219 | F1 = 0.9365 | Best Threshold = 0.6800 | Best F1 = 0.9434\n",
      "Fold 9 - New best F1: 0.9434 at threshold 0.6800 → model saved.\n",
      "[Fold 9] Epoch 16: Train Loss = 0.6786 | Val Loss = 1.0605 | Acc = 0.9489 | AUC = 0.9857 | Precision = 0.9275 | Recall = 0.9323 | F1 = 0.9299 | Best Threshold = 0.7200 | Best F1 = 0.9362\n",
      "[Fold 9] Epoch 17: Train Loss = 0.5802 | Val Loss = 1.1017 | Acc = 0.9432 | AUC = 0.9833 | Precision = 0.9263 | Recall = 0.9167 | F1 = 0.9215 | Best Threshold = 0.6700 | Best F1 = 0.9280\n",
      "[Fold 9] Epoch 18: Train Loss = 0.6033 | Val Loss = 1.1278 | Acc = 0.9432 | AUC = 0.9848 | Precision = 0.9309 | Recall = 0.9115 | F1 = 0.9211 | Best Threshold = 0.1800 | Best F1 = 0.9286\n",
      "[Fold 9] Epoch 19: Train Loss = 0.5290 | Val Loss = 1.1756 | Acc = 0.9432 | AUC = 0.9837 | Precision = 0.9402 | Recall = 0.9010 | F1 = 0.9202 | Best Threshold = 0.3700 | Best F1 = 0.9319\n",
      "[Fold 9] Epoch 20: Train Loss = 0.4955 | Val Loss = 1.2708 | Acc = 0.9451 | AUC = 0.9832 | Precision = 0.9454 | Recall = 0.9010 | F1 = 0.9227 | Best Threshold = 0.3900 | Best F1 = 0.9259\n",
      "[Fold 9] Epoch 21: Train Loss = 0.3928 | Val Loss = 1.2685 | Acc = 0.9470 | AUC = 0.9813 | Precision = 0.9457 | Recall = 0.9062 | F1 = 0.9255 | Best Threshold = 0.3800 | Best F1 = 0.9312\n",
      "[Fold 9] Epoch 22: Train Loss = 0.5087 | Val Loss = 1.2197 | Acc = 0.9489 | AUC = 0.9820 | Precision = 0.9508 | Recall = 0.9062 | F1 = 0.9280 | Best Threshold = 0.4200 | Best F1 = 0.9337\n",
      "[Fold 9] Epoch 23: Train Loss = 0.3403 | Val Loss = 1.2487 | Acc = 0.9432 | AUC = 0.9829 | Precision = 0.9309 | Recall = 0.9115 | F1 = 0.9211 | Best Threshold = 0.5700 | Best F1 = 0.9284\n",
      "[Fold 9] Epoch 24: Train Loss = 0.4210 | Val Loss = 1.1910 | Acc = 0.9413 | AUC = 0.9828 | Precision = 0.9215 | Recall = 0.9167 | F1 = 0.9191 | Best Threshold = 0.7200 | Best F1 = 0.9280\n",
      "Fold 9 - Early stopping at epoch 24\n",
      "\n",
      "📦 Starting Fold 10\n",
      "[Fold 10] Epoch 1: Train Loss = 14.9165 | Val Loss = 1.2557 | Acc = 0.9299 | AUC = 0.9859 | Precision = 0.8444 | Recall = 0.9896 | F1 = 0.9113 | Best Threshold = 0.6300 | Best F1 = 0.9343\n",
      "Fold 10 - New best F1: 0.9343 at threshold 0.6300 → model saved.\n",
      "[Fold 10] Epoch 2: Train Loss = 8.4012 | Val Loss = 0.8450 | Acc = 0.9337 | AUC = 0.9893 | Precision = 0.8618 | Recall = 0.9740 | F1 = 0.9144 | Best Threshold = 0.7800 | Best F1 = 0.9319\n",
      "[Fold 10] Epoch 3: Train Loss = 6.4904 | Val Loss = 0.7690 | Acc = 0.9470 | AUC = 0.9919 | Precision = 0.8832 | Recall = 0.9844 | F1 = 0.9310 | Best Threshold = 0.8700 | Best F1 = 0.9418\n",
      "Fold 10 - New best F1: 0.9418 at threshold 0.8700 → model saved.\n",
      "[Fold 10] Epoch 4: Train Loss = 4.8937 | Val Loss = 0.7705 | Acc = 0.9527 | AUC = 0.9904 | Precision = 0.9239 | Recall = 0.9479 | F1 = 0.9357 | Best Threshold = 0.5700 | Best F1 = 0.9403\n",
      "[Fold 10] Epoch 5: Train Loss = 3.5840 | Val Loss = 0.7031 | Acc = 0.9470 | AUC = 0.9919 | Precision = 0.9100 | Recall = 0.9479 | F1 = 0.9286 | Best Threshold = 0.8600 | Best F1 = 0.9358\n",
      "[Fold 10] Epoch 6: Train Loss = 2.9291 | Val Loss = 0.8045 | Acc = 0.9470 | AUC = 0.9899 | Precision = 0.9059 | Recall = 0.9531 | F1 = 0.9289 | Best Threshold = 0.7200 | Best F1 = 0.9399\n",
      "[Fold 10] Epoch 7: Train Loss = 2.7524 | Val Loss = 0.7028 | Acc = 0.9489 | AUC = 0.9894 | Precision = 0.9188 | Recall = 0.9427 | F1 = 0.9306 | Best Threshold = 0.3800 | Best F1 = 0.9364\n",
      "[Fold 10] Epoch 8: Train Loss = 3.6677 | Val Loss = 0.7497 | Acc = 0.9432 | AUC = 0.9906 | Precision = 0.8857 | Recall = 0.9688 | F1 = 0.9254 | Best Threshold = 0.8700 | Best F1 = 0.9347\n",
      "[Fold 10] Epoch 9: Train Loss = 2.1626 | Val Loss = 0.6607 | Acc = 0.9564 | AUC = 0.9918 | Precision = 0.9333 | Recall = 0.9479 | F1 = 0.9406 | Best Threshold = 0.6100 | Best F1 = 0.9452\n",
      "Fold 10 - New best F1: 0.9452 at threshold 0.6100 → model saved.\n",
      "[Fold 10] Epoch 10: Train Loss = 1.5433 | Val Loss = 0.5956 | Acc = 0.9621 | AUC = 0.9924 | Precision = 0.9300 | Recall = 0.9688 | F1 = 0.9490 | Best Threshold = 0.5500 | Best F1 = 0.9563\n",
      "Fold 10 - New best F1: 0.9563 at threshold 0.5500 → model saved.\n",
      "[Fold 10] Epoch 11: Train Loss = 1.1813 | Val Loss = 0.6820 | Acc = 0.9527 | AUC = 0.9913 | Precision = 0.9196 | Recall = 0.9531 | F1 = 0.9361 | Best Threshold = 0.6200 | Best F1 = 0.9430\n",
      "[Fold 10] Epoch 12: Train Loss = 1.1197 | Val Loss = 0.6794 | Acc = 0.9508 | AUC = 0.9907 | Precision = 0.9109 | Recall = 0.9583 | F1 = 0.9340 | Best Threshold = 0.5800 | Best F1 = 0.9460\n",
      "[Fold 10] Epoch 13: Train Loss = 1.0439 | Val Loss = 0.7622 | Acc = 0.9545 | AUC = 0.9908 | Precision = 0.9118 | Recall = 0.9688 | F1 = 0.9394 | Best Threshold = 0.8200 | Best F1 = 0.9430\n",
      "[Fold 10] Epoch 14: Train Loss = 0.9052 | Val Loss = 0.7619 | Acc = 0.9564 | AUC = 0.9898 | Precision = 0.9163 | Recall = 0.9688 | F1 = 0.9418 | Best Threshold = 0.5000 | Best F1 = 0.9418\n",
      "[Fold 10] Epoch 15: Train Loss = 0.7019 | Val Loss = 0.7359 | Acc = 0.9564 | AUC = 0.9898 | Precision = 0.9204 | Recall = 0.9635 | F1 = 0.9415 | Best Threshold = 0.5600 | Best F1 = 0.9439\n",
      "[Fold 10] Epoch 16: Train Loss = 0.7680 | Val Loss = 0.7783 | Acc = 0.9508 | AUC = 0.9913 | Precision = 0.9192 | Recall = 0.9479 | F1 = 0.9333 | Best Threshold = 0.7100 | Best F1 = 0.9421\n",
      "[Fold 10] Epoch 17: Train Loss = 0.5048 | Val Loss = 0.7250 | Acc = 0.9583 | AUC = 0.9909 | Precision = 0.9208 | Recall = 0.9688 | F1 = 0.9442 | Best Threshold = 0.7300 | Best F1 = 0.9463\n",
      "[Fold 10] Epoch 18: Train Loss = 0.5171 | Val Loss = 0.8430 | Acc = 0.9527 | AUC = 0.9900 | Precision = 0.9196 | Recall = 0.9531 | F1 = 0.9361 | Best Threshold = 0.3400 | Best F1 = 0.9421\n",
      "[Fold 10] Epoch 19: Train Loss = 0.5620 | Val Loss = 0.8046 | Acc = 0.9545 | AUC = 0.9898 | Precision = 0.9158 | Recall = 0.9635 | F1 = 0.9391 | Best Threshold = 0.6500 | Best F1 = 0.9409\n",
      "Fold 10 - Early stopping at epoch 19\n",
      "\n",
      "🎯 Best thresholds by fold:\n",
      "Fold 1: Best threshold = 0.6400\n",
      "Fold 2: Best threshold = 0.7000\n",
      "Fold 3: Best threshold = 0.7700\n",
      "Fold 4: Best threshold = 0.6600\n",
      "Fold 5: Best threshold = 0.1600\n",
      "Fold 6: Best threshold = 0.7700\n",
      "Fold 7: Best threshold = 0.4800\n",
      "Fold 8: Best threshold = 0.7900\n",
      "Fold 9: Best threshold = 0.6800\n",
      "Fold 10: Best threshold = 0.5500\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "best_thresholds = []\n",
    "val_targets_all = []\n",
    "val_probs_all = []\n",
    "\n",
    "for fold_id, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\n📦 Starting Fold {fold_id + 1}\")\n",
    "    \n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = FusionNetPlus().to(DEVICE)\n",
    "    best_threshold, val_probs, val_targets = train_fold(model, train_loader, val_loader, fold_id=fold_id + 1)\n",
    "    \n",
    "    best_thresholds.append(best_threshold)\n",
    "    val_probs_all.extend(val_probs)\n",
    "    val_targets_all.extend(val_targets)\n",
    "\n",
    "# ✅ In toàn bộ threshold cuối cùng sau tất cả các fold\n",
    "print(\"\\n🎯 Best thresholds by fold:\")\n",
    "for i, th in enumerate(best_thresholds):\n",
    "    print(f\"Fold {i + 1}: Best threshold = {th:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73dd6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_finder(model, train_loader, optimizer_class, criterion, \n",
    "#               lr_start=1e-7, lr_end=1, num_iters=100):\n",
    "#     model.train()\n",
    "#     lrs = []\n",
    "#     losses = []\n",
    "\n",
    "#     optimizer = optimizer_class(model.parameters(), lr=lr_start)\n",
    "#     lr_lambda = lambda x: (lr_end/lr_start)**(x/num_iters)\n",
    "#     scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "#     iter_loader = iter(train_loader)\n",
    "#     for i in range(num_iters):\n",
    "#         try:\n",
    "#             xb, yb = next(iter_loader)\n",
    "#         except StopIteration:\n",
    "#             iter_loader = iter(train_loader)\n",
    "#             xb, yb = next(iter_loader)\n",
    "\n",
    "#         xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "#         optimizer.zero_grad()\n",
    "#         preds = model(xb)\n",
    "#         loss = criterion(preds, yb)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#         current_lr = optimizer.param_groups[0]['lr']\n",
    "#         lrs.append(current_lr)\n",
    "#         losses.append(loss.item())\n",
    "\n",
    "#         if i % 10 == 0:\n",
    "#             print(f\"Iter {i:03d} | LR: {current_lr:.6f} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "#     return lrs, losses\n",
    "\n",
    "# def plot_lr_finder(lrs, losses):\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.plot(lrs, losses)\n",
    "#     plt.xscale('log')\n",
    "#     plt.xlabel(\"Learning Rate (log scale)\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.title(\"LR Finder\")\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b6faf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n🔍 Chạy LR Finder sau khi huấn luyện 5 fold...\")\n",
    "\n",
    "# # Tạo full loader từ toàn bộ dataset\n",
    "# full_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# model = FusionNetPlus().to(DEVICE)\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# # Gọi hàm LR Finder\n",
    "# lrs, losses = lr_finder(\n",
    "#     model=model,\n",
    "#     train_loader=full_loader,\n",
    "#     optimizer_class=torch.optim.AdamW,\n",
    "#     criterion=criterion,\n",
    "#     lr_start=1e-7,\n",
    "#     lr_end=1,\n",
    "#     num_iters=100\n",
    "# )\n",
    "\n",
    "# # Vẽ biểu đồ\n",
    "# plot_lr_finder(lrs, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d15cc430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [0.0007 , 0.00068, 0.00065]\n",
    "# best_f1 = 0\n",
    "# best_lr = None\n",
    "\n",
    "# for lr in learning_rates:\n",
    "#     print(f\"\\n🔍 Testing learning rate: {lr}\")\n",
    "#     model = FusionNetPlus().to(DEVICE)\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "#     criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "#     # Huấn luyện 3 epoch nhanh trên 1 fold (hoặc dùng fold 0 làm mẫu)\n",
    "#     for epoch in range(3):\n",
    "#         model.train()\n",
    "#         for xb, yb in train_loader:\n",
    "#             xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = criterion(model(xb), yb)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     all_probs, all_targets = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for xb, yb in val_loader:\n",
    "#             xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "#             preds = model(xb)\n",
    "#             all_probs.extend(preds.cpu().numpy().flatten())\n",
    "#             all_targets.extend(yb.cpu().numpy().flatten())\n",
    "\n",
    "#     probs = np.array(all_probs)\n",
    "#     targets = np.array(all_targets)\n",
    "#     preds_bin = (probs >= 0.5).astype(int)\n",
    "#     f1 = f1_score(targets, preds_bin)\n",
    "\n",
    "#     print(f\"📊 F1 = {f1:.4f} for lr = {lr}\")\n",
    "#     if f1 > best_f1:\n",
    "#         best_f1 = f1\n",
    "#         best_lr = lr\n",
    "\n",
    "# print(f\"\\n✅ Best Learning Rate: {best_lr} with F1 = {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c81731da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.1794435844492635)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.std(best_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d716758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6400, 0.7000, 0.7700, 0.6600, 0.1600, 0.7700, 0.4800, 0.7900, 0.6800, 0.5500, "
     ]
    }
   ],
   "source": [
    "for i in best_thresholds:\n",
    "    print(f\"{i:.4f}\", end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddb217a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Mean: 0.6711111111111108\n"
     ]
    }
   ],
   "source": [
    "cleaned_thresh = [t for t in best_thresholds if 0.4 <= t <= 0.8]\n",
    "threshold2 = np.mean(cleaned_thresh)\n",
    "print(\"New Mean:\", threshold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ff7a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true, y_probs):\n",
    "    thresholds = np.arange(0.1, 0.91, 0.01)\n",
    "    best_t = 0.5\n",
    "    best_f1 = 0.0\n",
    "    for t in thresholds:\n",
    "        preds = (y_probs >= t).astype(int)\n",
    "        f1 = f1_score(y_true, preds, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "    return best_t, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1ab8672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.995265\n",
      "Precision : 0.990678\n",
      "Recall    : 0.996354\n",
      "F1 Score  : 0.993508\n",
      "AUC       : 0.999517\n",
      "\n",
      "Global optimal threshold on all val: 0.6700 | F1 = 0.9210\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Đảm bảo model đang ở chế độ eval\n",
    "model.eval()\n",
    "\n",
    "# Dự đoán không cần gradient\n",
    "with torch.no_grad():\n",
    "    logits = model(X_tensor.to(DEVICE))  # đầu ra là logits\n",
    "    probs = torch.sigmoid(logits).cpu().numpy().flatten()  # chuyển logits → xác suất\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "# Chuyển ground truth sang numpy\n",
    "targets = y_tensor.cpu().numpy().flatten()\n",
    "\n",
    "# Tính các chỉ số đánh giá\n",
    "acc = accuracy_score(targets, preds)\n",
    "precision = precision_score(targets, preds, zero_division=0)\n",
    "recall = recall_score(targets, preds, zero_division=0)\n",
    "f1 = f1_score(targets, preds, zero_division=0)\n",
    "auc = roc_auc_score(targets, probs)\n",
    "\n",
    "# Tìm threshold tốt nhất\n",
    "val_probs_all = np.array(val_probs_all)\n",
    "val_targets_all = np.array(val_targets_all)\n",
    "\n",
    "global_threshold, global_f1 = find_best_threshold(val_targets_all, val_probs_all)\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Accuracy  : {acc:.6f}\")\n",
    "print(f\"Precision : {precision:.6f}\")\n",
    "print(f\"Recall    : {recall:.6f}\")\n",
    "print(f\"F1 Score  : {f1:.6f}\")\n",
    "print(f\"AUC       : {auc:.6f}\")\n",
    "print(f\"\\nGlobal optimal threshold on all val: {global_threshold:.4f} | F1 = {global_f1:.4f}\")\n",
    "\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c57d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3483809003</td>\n",
       "      <td>Title: flooded parking lot at emily fowler lib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3712805295</td>\n",
       "      <td>Title: larc de barà the roman arch of barà | D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>379845620</td>\n",
       "      <td>Title: highest point over the sea level that i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7343264988</td>\n",
       "      <td>Title: lagos after the rains | Description: af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3843337492</td>\n",
       "      <td>Title: flooded corley ave | Description: also ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "0  3483809003  Title: flooded parking lot at emily fowler lib...\n",
       "1  3712805295  Title: larc de barà the roman arch of barà | D...\n",
       "2   379845620  Title: highest point over the sea level that i...\n",
       "3  7343264988  Title: lagos after the rains | Description: af...\n",
       "4  3843337492  Title: flooded corley ave | Description: also ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# --- Đọc dữ liệu ---\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# --- Hàm chuyển user_tags từ chuỗi → list an toàn ---\n",
    "def safe_list(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            val = ast.literal_eval(x)\n",
    "            if isinstance(val, list):\n",
    "                return val\n",
    "        except Exception:\n",
    "            pass\n",
    "        return [x] if x else []\n",
    "    return []\n",
    "\n",
    "test_df[\"user_tags\"] = test_df[\"user_tags\"].apply(safe_list)\n",
    "\n",
    "# --- Hàm làm sạch text chuẩn --- (dùng lại từ train)\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = unicodedata.normalize(\"NFKC\", text)  # chuẩn hóa Unicode\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # xóa URL\n",
    "    text = re.sub(r\"[^\\w\\s\\u4e00-\\u9fff\\u3040-\\u30ff\\uac00-\\ud7af\\-\\_#]+\", \"\", text)  # giữ lại chữ, số, emoji, - _ #\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # rút gọn khoảng trắng\n",
    "    return text.lower().strip()\n",
    "\n",
    "# --- Làm sạch từng trường ---\n",
    "test_df[\"title\"] = test_df[\"title\"].fillna(\"\").astype(str).apply(clean_text)\n",
    "test_df[\"description\"] = test_df[\"description\"].fillna(\"\").astype(str).apply(clean_text)\n",
    "test_df[\"user_tags\"] = test_df[\"user_tags\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else str(x))\n",
    "test_df[\"user_tags\"] = test_df[\"user_tags\"].apply(clean_text)\n",
    "\n",
    "# --- Tạo văn bản đầu vào cho BLIP ---\n",
    "test_df[\"text\"] = test_df.apply(\n",
    "    lambda row: f\"Title: {row['title']} | Description: {row['description']} | Tags: {row['user_tags']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ✅ Kết quả\n",
    "test_df[[\"id\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5000e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số ảnh hợp lệ (không bắt đầu bằng '._'): 1320\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Đường dẫn thư mục chứa ảnh\n",
    "IMG_TEST_DIR = os.path.join(\"../data/testset_images\", \"testset_images\")\n",
    "\n",
    "# Các đuôi ảnh hợp lệ\n",
    "valid_exts = [\".jpg\", \".png\"]\n",
    "\n",
    "# Lọc file ảnh hợp lệ\n",
    "image_files = [\n",
    "    f for f in os.listdir(IMG_TEST_DIR)\n",
    "    if os.path.isfile(os.path.join(IMG_TEST_DIR, f))\n",
    "    and not f.startswith(\"._\")\n",
    "    and os.path.splitext(f.lower())[1] in valid_exts\n",
    "]\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Tổng số ảnh hợp lệ (không bắt đầu bằng '._'): {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "891f84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_path_test(image_id, exts=[\".jpg\", \".png\"]):\n",
    "    for ext in exts:\n",
    "        path = os.path.join(IMG_TEST_DIR, f\"{image_id}{ext}\")\n",
    "        if os.path.isfile(path):\n",
    "            return path\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1b0fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing ảnh ---\n",
    "image_transform_test = transforms.Compose([\n",
    "    transforms.Resize((600, 600)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e3707e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_b7_features_test(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image_transform_test(image).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            features = b7_model(image).squeeze(0)\n",
    "        return features.cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Lỗi ảnh tại {image_path}: {e}\")\n",
    "        return np.zeros(2560, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da94751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test features: 100%|██████████| 1320/1320 [02:22<00:00,  9.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_features = []\n",
    "error_count = 0\n",
    "\n",
    "expected_b7 = (2560,)\n",
    "expected_deberta = (768,)\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Extracting test features\"):\n",
    "    try:\n",
    "        image_id = str(int(row[\"id\"]))\n",
    "        image_path = find_image_path_test(image_id)\n",
    "        text_input = row[\"text\"]\n",
    "\n",
    "        # Mặc định zero vector\n",
    "        img_feat = np.zeros(expected_b7, dtype=np.float32)\n",
    "        txt_feat = np.zeros(expected_deberta, dtype=np.float32)\n",
    "\n",
    "        # Image features\n",
    "        if image_path is not None:\n",
    "            img_feat = extract_b7_features_test(image_path)\n",
    "        else:\n",
    "            print(f\"Missing image: {image_id}\")\n",
    "\n",
    "        # Text features\n",
    "        if isinstance(text_input, str):\n",
    "            txt_feat = extract_deberta_features(text_input)\n",
    "\n",
    "        # Validate shape\n",
    "        if img_feat.shape != expected_b7:\n",
    "            print(f\"Wrong shape for image {image_id}\")\n",
    "            img_feat = np.zeros(expected_b7)\n",
    "        if txt_feat.shape != expected_deberta:\n",
    "            print(f\"Wrong shape for text {image_id}\")\n",
    "            txt_feat = np.zeros(expected_deberta)\n",
    "\n",
    "        # Combine features\n",
    "        combined_feat = np.concatenate([img_feat, txt_feat])\n",
    "        all_features.append(combined_feat)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at idx {idx}, id {row['id']}: {e}\")\n",
    "        error_count += 1\n",
    "        combined_feat = np.concatenate([\n",
    "            np.zeros(expected_b7, dtype=np.float32),\n",
    "            np.zeros(expected_deberta, dtype=np.float32)\n",
    "        ])\n",
    "        all_features.append(combined_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67f5bf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu b7_deberta_features_test.npy\n",
      "Shape: (1320, 3328)\n",
      "Số lượng lỗi: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array and save\n",
    "all_features = np.stack(all_features)\n",
    "np.save(\"b7_deberta_features_test.npy\", all_features)\n",
    "print(\"Đã lưu b7_deberta_features_test.npy\")\n",
    "print(f\"Shape: {all_features.shape}\")\n",
    "print(f\"Số lượng lỗi: {error_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b42631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed0d1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_test = np.load(\"b7_deberta_features_test.npy\")  # Đã được đồng bộ (shape: M, 3328)\n",
    "X_test_tensor = torch.tensor(b7_test, dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd823529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with Fold 1\n",
      "Predicting with Fold 2\n",
      "Predicting with Fold 3\n",
      "Predicting with Fold 4\n",
      "Predicting with Fold 5\n",
      "Predicting with Fold 6\n",
      "Predicting with Fold 7\n",
      "Predicting with Fold 8\n",
      "Predicting with Fold 9\n",
      "Predicting with Fold 10\n"
     ]
    }
   ],
   "source": [
    "NUM_FOLDS = 10\n",
    "all_probs = []\n",
    "\n",
    "for fold in range(1, NUM_FOLDS + 1):\n",
    "    print(f\"Predicting with Fold {fold}\")\n",
    "    model = FusionNetPlus().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(f\"best_model_fold{fold}.pt\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_test_tensor)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy().flatten()  # Chuyển logits → xác suất\n",
    "        all_probs.append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80eb65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_probs = np.mean(all_probs, axis=0)\n",
    "ensemble_preds = (ensemble_probs >= threshold2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fe4d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6711111111111108\n",
      "0.6699999999999997\n"
     ]
    }
   ],
   "source": [
    "print(threshold2)\n",
    "print(global_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e72e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_df.copy()  # test_df phải có cột 'id'\n",
    "results_df[\"label\"] = ensemble_preds\n",
    "results_df[\"probability\"] = ensemble_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b00ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df[[\"id\", \"label\", \"probability\"]].copy()\n",
    "results_df.sort_values(by=\"probability\", ascending=False, inplace=True)\n",
    "results_df.to_csv(\"../create_output/result_b7+bert.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5c7f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = results_df[[\"id\", \"label\"]].copy()\n",
    "submission_df.to_csv(\"submission_b7+bert.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fe5a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng dự đoán là 1: 468\n"
     ]
    }
   ],
   "source": [
    "num_positives = (results_df[\"label\"] == 1).sum()\n",
    "print(f\"Số lượng dự đoán là 1: {num_positives}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
